{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras import layers, Sequential, mixed_precision\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv(file_path):\n",
    "    '''\n",
    "    Read CSV file and return data as numpy array\n",
    "    '''\n",
    "    df = pd.read_csv(file_path)\n",
    "    if \"class\" in list(df.columns.values):\n",
    "        df = df.drop(\"class\", axis=1)\n",
    "    data = np.array(df,dtype=object)\n",
    "    data = data.astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 300)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv(\"init_demo.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602175712585449"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_for_one_file(data, var):\n",
    "    current_max = 0\n",
    "    vars = {\"x\": 0, \"y\": 1, \"z\": 2}\n",
    "    for i in range(data.shape[0]):\n",
    "        frame = data[i]\n",
    "        frame = frame.reshape((-1, 4))\n",
    "        for j in range(frame.shape[0]):\n",
    "            if frame[j][vars[var]] > current_max:\n",
    "                current_max = frame[j][vars[var]]\n",
    "    \n",
    "    return current_max\n",
    "find_max_for_one_file(data, \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_matrix_for_frame(data, idx, x_dim, y_dim):\n",
    "   \n",
    "    # create a matrix of all zeros\n",
    "    matrix = np.zeros((x_dim//10,y_dim//10))\n",
    "    # fill the matrix with random values\n",
    "    frame = data[idx]\n",
    "    frame = frame.reshape((-1, 4))\n",
    "    for j in range(len(frame)):\n",
    "        matrix[int(frame[j][0] * 1000/10)][int(frame[j][1] * 1000/10)] = j\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialize_matrix_for_frame() missing 2 required positional arguments: 'x_dim' and 'y_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matrix \u001b[39m=\u001b[39m initialize_matrix_for_frame(data, \u001b[39m0\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize_matrix_for_frame() missing 2 required positional arguments: 'x_dim' and 'y_dim'"
     ]
    }
   ],
   "source": [
    "matrix = initialize_matrix_for_frame(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# plot the matrix\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m coords \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(matrix)\n\u001b[1;32m      4\u001b[0m \u001b[39m# Plot the non-zero elements\u001b[39;00m\n\u001b[1;32m      5\u001b[0m plt\u001b[39m.\u001b[39mscatter(coords[\u001b[39m0\u001b[39m], coords[\u001b[39m1\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the matrix\n",
    "coords = np.nonzero(matrix)\n",
    "\n",
    "# Plot the non-zero elements\n",
    "plt.scatter(coords[0], coords[1])\n",
    "\n",
    "# Set the x and y limits\n",
    "plt.xlim(0, matrix.shape[0])\n",
    "plt.ylim(0, matrix.shape[1])\n",
    "\n",
    "# Set the labels for the axes\n",
    "plt.xlabel('Row number')\n",
    "plt.ylabel('Column number')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensor(data, x_dim=1500, y_dim=3200, sliding_window_size=10):\n",
    "    # check for max value in x and y, which will then be used for the shape of the matrix\n",
    "\n",
    "    for i in range(len(data) - sliding_window_size + 1):\n",
    "        # print(i, len(data) - sliding_window_size + 1)\n",
    "        tensor = np.zeros((sliding_window_size, x_dim//10,y_dim//10))\n",
    "        for j in range(i, i + 10):\n",
    "            new_matrix = initialize_matrix_for_frame(data, j, x_dim, y_dim)\n",
    "            tensor[j-i] = new_matrix\n",
    "        yield tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 150, 320)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_arr = np.empty((0,10,150,320))\n",
    "tensor_gen = generate_tensor(data, 1500, 3200, sliding_window_size=10)\n",
    "arr_to_add = np.expand_dims(next(tensor_gen), axis=0)\n",
    "test_arr = np.concatenate((test_arr,  arr_to_add), axis=0)\n",
    "test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = \"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/data_augmentation/data_four_labels_augmentation\"\n",
    "\n",
    "def find_max_dim__for_entire_folder(path, sliding_window_size = 10):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    max_x_dim = 0\n",
    "    max_y_dim = 0\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%4 == 0:\n",
    "                    data = read_csv(os.path.join(path, label, file))\n",
    "                    max_x = find_max_for_one_file(data, \"x\") * 1000\n",
    "                    max_y = find_max_for_one_file(data, \"y\") * 1000\n",
    "                    x_dim = round(math.ceil(max_x/100)*100, -1)\n",
    "                    y_dim = round(math.ceil(max_y/100)*100, -1)\n",
    "                    if max_x_dim < x_dim:\n",
    "                        max_x_dim = x_dim\n",
    "                    if max_y_dim < y_dim:\n",
    "                        max_y_dim = y_dim\n",
    "                i += 1\n",
    "        print(label, max_x_dim, max_y_dim)\n",
    "    return max_x_dim, max_y_dim\n",
    "# find_max_dim__for_entire_folder(path, sliding_window_size = 10)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 dog 1E8k8gI_xYk3420_reflection_rotation_15_scale_0.2_translate_0.5_left.csv\n",
      "2 200 dog Ou-7SRWs0e0128_reflection_translate_0.5_left.csv\n",
      "3 300 dog 498gWK7nFCI20_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "4 400 dog FBD4NFz4QaA4056_reflection_rotation_15_translate_0.5_left.csv_projective_geo_9_True.csv\n",
      "5 500 dog R_ES8RZua1g11082_reflection.csv_projective_geo_10_True.csv\n",
      "6 600 dog R_ES8RZua1g11185_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_6_False.csv\n",
      "7 700 dog Ag5VPvAe8PA5557_reflection_rotation_15_translation_0.5.csv_projective_geo_14_False.csv\n",
      "8 800 dog Ag5VPvAe8PA5557_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "9 900 dog ohjlMkxe1Wc1731_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "10 1000 dog g59_3vr_NT01632_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "11 1100 dog sUC-XDC5TvA2368_scale_0.2_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "12 1200 dog N5ZUQxL4__c0_reflection_rotation_15_translation_0.5.csv\n",
      "13 1300 dog 1E8k8gI_xYk3420_reflection_scale_0.2_translate_0.5_left.csv_projective_geo_12_True.csv\n",
      "14 1400 dog TXmuXH4fmu00_rotation_15_scale_0.2.csv_projective_geo_9_True.csv\n",
      "15 1500 dog KsvdFnvMNAA5553_translation_0.5_scale_0.2.csv_projective_geo_13_True.csv\n",
      "16 1600 dog N5ZUQxL4__c0_reflection_translation_0.5_translate_0.5_left.csv_projective_geo_14_False.csv\n",
      "17 1700 dog ohjlMkxe1Wc1831_reflection_scale_0.2.csv_projective_geo_11_True.csv\n",
      "18 1800 dog catBjk1p2bk0_reflection_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "19 1900 dog catBjk1p2bk0_reflection_translate_0.5_left.csv_projective_geo_12_True.csv\n",
      "20 2000 dog rIlQQTN2b586887_reflection_rotation_15_translation_0.5_scale_0.2.csv\n",
      "21 2100 dog Ou-7SRWs0e041_reflection_rotation_15_translate_0.5_left.csv_projective_geo_5_False.csv\n",
      "22 2200 dog sUC-XDC5TvA2228_reflection_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_9_False.csv\n",
      "23 2300 dog UXetwN_cI5A8984_reflection_rotation_15_scale_0.2.csv_projective_geo_6_False.csv\n",
      "24 2400 dog 498gWK7nFCI20_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_12_False.csv\n",
      "25 2500 dog SJAhRxI7i9c1026_reflection_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "26 2600 dog Ou-7SRWs0e0308_reflection_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "27 2700 dog sUC-XDC5TvA2228_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "28 2800 dog 1E8k8gI_xYk3420_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "29 2900 dog KRrKqGEGdMg18884_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "30 3000 dog sUC-XDC5TvA2228_reflection_rotation_15.csv_projective_geo_9_True.csv\n",
      "31 3100 dog lvqGMGFmuV4325_reflection_scale_0.2.csv_projective_geo_12_True.csv\n",
      "32 3200 dog rIlQQTN2b586887_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "33 3300 dog R_ES8RZua1g11185_rotation_15_scale_0.2.csv_projective_geo_11_False.csv\n",
      "34 3400 dog FBD4NFz4QaA4056_reflection_rotation_15.csv_projective_geo_7_False.csv\n",
      "1 100 milk qAF88xW4xPY3438_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_11_True.csv\n",
      "2 200 milk 5yelilk0pD40_reflection_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "3 300 milk 6Mmgrtw_Zro869_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "4 400 milk rkQZQhloXuE4918_reflection_rotation_15_scale_0.2.csv_projective_geo_13_False.csv\n",
      "5 500 milk XtkDeYBnR8o4846_scale_0.2.csv_projective_geo_8_False.csv\n",
      "6 600 milk He0k3ddd67A8107_reflection_rotation_15_translation_0.5.csv_projective_geo_12_True.csv\n",
      "7 700 milk CmKYKBQuHf46771_reflection_scale_0.2_translate_0.5_left.csv\n",
      "8 800 milk 2sGQuduhAf43239_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_14_False.csv\n",
      "9 900 milk qAF88xW4xPY3471_reflection_rotation_15_scale_0.2.csv_projective_geo_8_True.csv\n",
      "10 1000 milk jDCw7stJaM43664_reflection_translation_0.5.csv_projective_geo_14_True.csv\n",
      "11 1100 milk n0PdKty8WRA5460_translation_0.5.csv_projective_geo_12_False.csv\n",
      "12 1200 milk MIPvaUKFA4c750_reflection_scale_0.2.csv_projective_geo_7_False.csv\n",
      "13 1300 milk qAF88xW4xPY3438_reflection_rotation_15_scale_0.2.csv\n",
      "14 1400 milk JD_CiyDFnkM0_reflection_rotation_15_translate_0.5_left.csv\n",
      "15 1500 milk CmKYKBQuHf46771_rotation_15_translation_0.5.csv\n",
      "16 1600 milk CmKYKBQuHf46771_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "17 1700 milk PRtOyut96Ps0_translation_0.5_scale_0.2.csv\n",
      "18 1800 milk AW2kJeqxKds0_reflection_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "19 1900 milk qAF88xW4xPY3368_reflection_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "20 2000 milk wjbWyQLPqwQ0_translation_0.5.csv_projective_geo_6_True.csv\n",
      "21 2100 milk 6UrcyZ-QeiU390_reflection_scale_0.2.csv_projective_geo_6_True.csv\n",
      "22 2200 milk MIPvaUKFA4c750_translate_0.5_left.csv_projective_geo_7_False.csv\n",
      "23 2300 milk vE4RFGPqGqY5296_translation_0.5.csv_projective_geo_12_True.csv\n",
      "24 2400 milk 6UrcyZ-QeiU550_scale_0.2_translate_0.5_left.csv_projective_geo_6_False.csv\n",
      "25 2500 milk vE4RFGPqGqY5296_reflection_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_11_True.csv\n",
      "26 2600 milk 6UrcyZ-QeiU300_translation_0.5_translate_0.5_left.csv_projective_geo_10_True.csv\n",
      "27 2700 milk FNt4N8WFuVY16613_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_8_False.csv\n",
      "28 2800 milk 6UrcyZ-QeiU390_translation_0.5.csv_projective_geo_13_False.csv\n",
      "29 2900 milk n0PdKty8WRA5460_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "30 3000 milk MIPvaUKFA4c750_reflection_translation_0.5_translate_0.5_left.csv\n",
      "31 3100 milk shPBfkIYYpU26385_reflection_rotation_15_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "32 3200 milk shPBfkIYYpU26385_rotation_15.csv\n",
      "33 3300 milk shPBfkIYYpU26282_translate_0.5_left.csv_projective_geo_5_False.csv\n",
      "34 3400 milk creSIQ3owuo0_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "35 3500 milk 6UrcyZ-QeiU660_rotation_15.csv_projective_geo_11_True.csv\n",
      "36 3600 milk 6UrcyZ-QeiU550_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_12_False.csv\n",
      "37 3700 milk jDCw7stJaM43664_reflection_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_11_False.csv\n",
      "38 3800 milk shPBfkIYYpU26282_reflection_rotation_15_scale_0.2_translate_0.5_left.csv\n",
      "39 3900 milk 6UrcyZ-QeiU390_reflection_rotation_15_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "40 4000 milk 6UrcyZ-QeiU550_scale_0.2.csv_projective_geo_7_False.csv\n",
      "41 4100 milk shPBfkIYYpU26385_rotation_15_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "42 4200 milk k0T-yY_HrEQ325_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "43 4300 milk FrZzNdspSbw0_reflection_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "44 4400 milk FrZzNdspSbw0_reflection_translation_0.5_translate_0.5_left.csv\n",
      "45 4500 milk XtkDeYBnR8o4846_translation_0.5_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "1 100 coffee FEZ2sZmYRbI0_rotation_15_scale_0.2.csv_projective_geo_9_True.csv\n",
      "2 200 coffee CxTSVyM-ij013680_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_5_True.csv\n",
      "3 300 coffee eeHS78JyN706789_translate_0.5_left.csv_projective_geo_10_False.csv\n",
      "4 400 coffee ax2UGtA8h3E2137_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_12_True.csv\n",
      "5 500 coffee hUrfB8bikfw1437_reflection_translation_0.5_translate_0.5_left.csv_projective_geo_10_True.csv\n",
      "6 600 coffee q38xuZH11jw4313_translate_0.5_left.csv_projective_geo_5_False.csv\n",
      "7 700 coffee Rz2NwFuHic80_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_8_False.csv\n",
      "8 800 coffee 2sGQuduhAf41354_reflection_scale_0.2.csv_projective_geo_13_True.csv\n",
      "9 900 coffee ax2UGtA8h3E2137_reflection_rotation_15_scale_0.2.csv_projective_geo_10_False.csv\n",
      "10 1000 coffee eeHS78JyN706909_rotation_15_translate_0.5_left.csv\n",
      "11 1100 coffee FNt4N8WFuVY15970_rotation_15_scale_0.2_translate_0.5_left.csv\n",
      "12 1200 coffee hUrfB8bikfw1437_rotation_15_translate_0.5_left.csv\n",
      "13 1300 coffee ax2UGtA8h3E2137_rotation_15_translation_0.5.csv_projective_geo_9_False.csv\n",
      "14 1400 coffee KFSLtsOwZiU1121_reflection_rotation_15_translation_0.5.csv_projective_geo_14_False.csv\n",
      "15 1500 coffee vE4RFGPqGqY5721_reflection.csv\n",
      "16 1600 coffee CSj7IScvZnE5770_reflection_translation_0.5.csv_projective_geo_12_True.csv\n",
      "17 1700 coffee FEZ2sZmYRbI0_reflection_rotation_15.csv_projective_geo_12_False.csv\n",
      "18 1800 coffee _wijo648v0g3208_reflection_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "19 1900 coffee FNt4N8WFuVY15740_reflection_translation_0.5.csv_projective_geo_8_True.csv\n",
      "20 2000 coffee FUHOIo_8o9w4459_translation_0.5.csv\n",
      "21 2100 coffee uVLwe5c7LaQ0_rotation_15.csv_projective_geo_8_True.csv\n",
      "22 2200 coffee n0PdKty8WRA2084.csv\n",
      "23 2300 coffee Rz2NwFuHic80_reflection_scale_0.2_translate_0.5_left.csv_projective_geo_10_False.csv\n",
      "24 2400 coffee CxTSVyM-ij013790_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "25 2500 coffee FEZ2sZmYRbI0_reflection_translation_0.5.csv\n",
      "26 2600 coffee sErq0TJMKEo4730_translate_0.5_left.csv_projective_geo_12_True.csv\n",
      "27 2700 coffee CxTSVyM-ij013680.csv_projective_geo_14_True.csv\n",
      "28 2800 coffee 2sGQuduhAf41354_rotation_15_scale_0.2.csv_projective_geo_7_True.csv\n",
      "29 2900 coffee FEZ2sZmYRbI0_scale_0.2.csv\n",
      "1 100 door j8a5Z-5lUwo679_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "2 200 door j8a5Z-5lUwo679_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "3 300 door WO-PVfhctjM0_reflection_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "4 400 door nHnqAu_1K-c12221_rotation_15_translation_0.5.csv_projective_geo_11_False.csv\n",
      "5 500 door RAtOGNDP0dg3854_rotation_15_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "6 600 door nHnqAu_1K-c12221_rotation_15_translate_0.5_left.csv\n",
      "7 700 door K4lo0NZDlH86823_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "8 800 door Y24sRF_8lFU0_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "9 900 door Y24sRF_8lFU0.csv_projective_geo_6_True.csv\n",
      "10 1000 door nHnqAu_1K-c12221_reflection_translation_0.5.csv_projective_geo_12_True.csv\n",
      "11 1100 door Ip1L7UrulFE0_reflection_rotation_15_scale_0.2.csv_projective_geo_11_True.csv\n",
      "12 1200 door rnr_aY0X0dQ5683_translation_0.5_translate_0.5_left.csv_projective_geo_9_False.csv\n",
      "13 1300 door SiTBL7DYzZQ1382_reflection_rotation_15_scale_0.2.csv\n",
      "14 1400 door 2VB3WN8adyM7255_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "15 1500 door WCGDN5CniTY0_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_14_False.csv\n",
      "16 1600 door WO-PVfhctjM0_translate_0.5_left.csv\n",
      "17 1700 door 2VB3WN8adyM7255_reflection_rotation_15_translate_0.5_left.csv_projective_geo_5_True.csv\n",
      "18 1800 door xzIU5tmBrLc0_reflection_translation_0.5.csv_projective_geo_14_False.csv\n",
      "19 1900 door eMZdggjnLQA5067_reflection_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "20 2000 door K4lo0NZDlH86823_scale_0.2_translate_0.5_left.csv\n",
      "21 2100 door A0TTA7Rlkzc2027_rotation_15_translate_0.5_left.csv_projective_geo_10_False.csv\n",
      "22 2200 door iWJgaNo9Z041756_reflection_rotation_15_scale_0.2.csv\n",
      "23 2300 door fNg_sJ9f8EI13768_reflection_translate_0.5_left.csv\n",
      "24 2400 door xzIU5tmBrLc0_reflection_translation_0.5_scale_0.2.csv_projective_geo_14_False.csv\n",
      "25 2500 door WCGDN5CniTY0_translation_0.5_translate_0.5_left.csv_projective_geo_8_True.csv\n",
      "26 2600 door nHnqAu_1K-c12667_reflection_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "27 2700 door Ip1L7UrulFE0_reflection_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_11_True.csv\n"
     ]
    }
   ],
   "source": [
    " # 80/20 split\n",
    "x_dim = 1500\n",
    "y_dim = 3200\n",
    "sliding_window_size = 10\n",
    "\n",
    "def process_entire_folder(path, sliding_window_size = 10, x_dim=1500, y_dim=3200):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_val\n",
    "    global y_val\n",
    "    X_train = np.empty((0,10,x_dim//10,y_dim//10))\n",
    "    y_train = []\n",
    "    X_val = np.empty((0,10,x_dim//10,y_dim//10))\n",
    "    y_val = []\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%100 == 0:\n",
    "                    j += 1\n",
    "                    print(j, i, label, file)\n",
    "                    tensor_generator = generate_tensor(data, x_dim, y_dim, sliding_window_size)\n",
    "                    for tensor in tensor_generator:\n",
    "                        arr_to_add = np.expand_dims(tensor, axis=0)\n",
    "                        if j%5 == 0:\n",
    "                            # add to validation set\n",
    "                            X_val = np.concatenate((X_val,  arr_to_add), axis=0)\n",
    "                            y_val.append(label)\n",
    "                        else:\n",
    "                            X_train = np.concatenate((X_train,  arr_to_add), axis=0)\n",
    "                            y_train.append(label)\n",
    "                i += 1\n",
    "process_entire_folder(path, sliding_window_size, x_dim, y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(175, 10, 150, 320)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(770, 10, 150, 320)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000 dog g59_3vr_NT01632_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "2 2000 dog rIlQQTN2b586887_reflection_rotation_15_translation_0.5_scale_0.2.csv\n",
      "3 3000 dog sUC-XDC5TvA2228_reflection_rotation_15.csv_projective_geo_9_True.csv\n",
      "1 1000 milk jDCw7stJaM43664_reflection_translation_0.5.csv_projective_geo_14_True.csv\n",
      "2 2000 milk wjbWyQLPqwQ0_translation_0.5.csv_projective_geo_6_True.csv\n",
      "3 3000 milk MIPvaUKFA4c750_reflection_translation_0.5_translate_0.5_left.csv\n",
      "4 4000 milk 6UrcyZ-QeiU550_scale_0.2.csv_projective_geo_7_False.csv\n",
      "1 1000 coffee eeHS78JyN706909_rotation_15_translate_0.5_left.csv\n",
      "2 2000 coffee FUHOIo_8o9w4459_translation_0.5.csv\n",
      "1 1000 door nHnqAu_1K-c12221_reflection_translation_0.5.csv_projective_geo_12_True.csv\n",
      "2 2000 door K4lo0NZDlH86823_scale_0.2_translate_0.5_left.csv\n"
     ]
    }
   ],
   "source": [
    "x_dim = 1500\n",
    "y_dim = 3200\n",
    "sliding_window_size = 10\n",
    "\n",
    "def process_entire_folder(path, sliding_window_size = 10, x_dim=1500, y_dim=3200):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_val\n",
    "    global y_val\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%1000 == 0:\n",
    "                    j += 1\n",
    "                    print(j, i, label, file)\n",
    "                    tensor_generator = generate_tensor(data, x_dim, y_dim, sliding_window_size)\n",
    "                    for tensor in tensor_generator:\n",
    "                        \n",
    "                        if j%5 == 0:\n",
    "                            # add to validation set\n",
    "                            X_val.append(tensor)\n",
    "                            y_val.append(label)\n",
    "                        else:\n",
    "                            X_train.append(tensor)\n",
    "                            y_train.append(label)\n",
    "                i += 1\n",
    "process_entire_folder(path, sliding_window_size, x_dim, y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_label(label_arr):    \n",
    "#should be between 0 and 3\n",
    "    dicti={\"coffee\": 0, \"dog\": 1, \"door\": 2, \"milk\": 3}\n",
    "    # for element in df_labels:\n",
    "    #     element = dicti[element]\n",
    "    for i in range(len(label_arr)):\n",
    "        label_arr[i] = dicti[label_arr[i]]\n",
    "    return label_arr\n",
    "y_train = reformat_label(y_train)\n",
    "y_val = reformat_label(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]]),\n",
       " [2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train,Y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_val,Y_val = shuffle(X_val, y_val, random_state=0)\n",
    "X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(770, 1) (175, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(Y_train).reshape((-1, 1))\n",
    "Y_val = np.array(Y_val).reshape((-1, 1))\n",
    "print(Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/training_models/mediapipe/Sliding_window_dense-Layers/AUGMENTED-CNN.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 8, 148, 318, 32)   896       \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 2, 2, 2, 32)      0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2, 2, 2, 32)       0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,100\n",
      "Trainable params: 100,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv3D(32,(3,3,3),activation='relu',input_shape=(10, 150, 320, 1)))\n",
    "model.add(layers.MaxPooling3D((5, 75, 160), padding=\"same\"))\n",
    "# model.add(layers.Conv3D(64,(2,2,2),activation='relu'))\n",
    "# model.add(layers.MaxPooling3D((2, 38, 80), padding=\"same\"))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,'relu'))\n",
    "model.add(layers.Dense(128,'relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(128,'relu'))\n",
    "# model.add(layers.Dense(64,'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4,'softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'MaxPool3D' used by {{node sequential_5/max_pooling3d_4/MaxPool3D}} with these attrs: [ksize=[1, 5, 75, 160, 1], padding=\"SAME\", T=DT_HALF, strides=[1, 5, 75, 160, 1], data_format=\"NDHWC\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_BFLOAT16, DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n\n\t [[sequential_5/max_pooling3d_4/MaxPool3D]] [Op:__inference_train_function_3726]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit data to model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train,\n\u001b[1;32m      3\u001b[0m             batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m             validation_data\u001b[39m=\u001b[39;49m(X_val,Y_val), callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/asl-converter/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/asl-converter/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPool3D' used by {{node sequential_5/max_pooling3d_4/MaxPool3D}} with these attrs: [ksize=[1, 5, 75, 160, 1], padding=\"SAME\", T=DT_HALF, strides=[1, 5, 75, 160, 1], data_format=\"NDHWC\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_BFLOAT16, DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n\n\t [[sequential_5/max_pooling3d_4/MaxPool3D]] [Op:__inference_train_function_3726]"
     ]
    }
   ],
   "source": [
    "# Fit data to model\n",
    "history = model.fit(X_train, Y_train,\n",
    "            batch_size=32,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_data=(X_val,Y_val), callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl-converter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
