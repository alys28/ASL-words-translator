{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "from tensorflow.keras import layers, Sequential, mixed_precision\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_precision.set_global_policy('mixed_float16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_csv(file_path):\n",
    "    '''\n",
    "    Read CSV file and return data as numpy array\n",
    "    '''\n",
    "    df = pd.read_csv(file_path)\n",
    "    if \"class\" in list(df.columns.values):\n",
    "        df = df.drop(\"class\", axis=1)\n",
    "    data = np.array(df,dtype=object)\n",
    "    data = data.astype(float)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = read_csv(\"init_demo.csv\")\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8602175712585449"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_max_for_one_file(data, var):\n",
    "    current_max = 0\n",
    "    vars = {\"x\": 0, \"y\": 1, \"z\": 2}\n",
    "    for i in range(data.shape[0]):\n",
    "        frame = data[i]\n",
    "        frame = frame.reshape((-1, 4))\n",
    "        for j in range(frame.shape[0]):\n",
    "            if frame[j][vars[var]] > current_max:\n",
    "                current_max = frame[j][vars[var]]\n",
    "    \n",
    "    return current_max\n",
    "find_max_for_one_file(data, \"x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_matrix_for_frame(data, idx, x_dim, y_dim):\n",
    "   \n",
    "    # create a matrix of all zeros\n",
    "    matrix = np.zeros((x_dim//10,y_dim//10))\n",
    "    # fill the matrix with random values\n",
    "    frame = data[idx]\n",
    "    frame = frame.reshape((-1, 4))\n",
    "    for j in range(len(frame)):\n",
    "        matrix[int(frame[j][0] * 1000/10)][int(frame[j][1] * 1000/10)] = j\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "initialize_matrix_for_frame() missing 2 required positional arguments: 'x_dim' and 'y_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[132], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m matrix \u001b[39m=\u001b[39m initialize_matrix_for_frame(data, \u001b[39m0\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: initialize_matrix_for_frame() missing 2 required positional arguments: 'x_dim' and 'y_dim'"
     ]
    }
   ],
   "source": [
    "matrix = initialize_matrix_for_frame(data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# plot the matrix\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m coords \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mnonzero(matrix)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Plot the non-zero elements\u001b[39;00m\n\u001b[0;32m      5\u001b[0m plt\u001b[39m.\u001b[39mscatter(coords[\u001b[39m0\u001b[39m], coords[\u001b[39m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'matrix' is not defined"
     ]
    }
   ],
   "source": [
    "# plot the matrix\n",
    "coords = np.nonzero(matrix)\n",
    "\n",
    "# Plot the non-zero elements\n",
    "plt.scatter(coords[0], coords[1])\n",
    "\n",
    "# Set the x and y limits\n",
    "plt.xlim(0, matrix.shape[0])\n",
    "plt.ylim(0, matrix.shape[1])\n",
    "\n",
    "# Set the labels for the axes\n",
    "plt.xlabel('Row number')\n",
    "plt.ylabel('Column number')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensor(data, x_dim=1500, y_dim=3200, sliding_window_size=10):\n",
    "    # check for max value in x and y, which will then be used for the shape of the matrix\n",
    "\n",
    "    for i in range(len(data) - sliding_window_size + 1):\n",
    "        # print(i, len(data) - sliding_window_size + 1)\n",
    "        tensor = np.zeros((sliding_window_size, x_dim//10,y_dim//10))\n",
    "        for j in range(i, i + 10):\n",
    "            new_matrix = initialize_matrix_for_frame(data, j, x_dim, y_dim)\n",
    "            tensor[j-i] = new_matrix\n",
    "        yield tensor\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m test_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mempty((\u001b[39m0\u001b[39m,\u001b[39m10\u001b[39m,\u001b[39m150\u001b[39m,\u001b[39m320\u001b[39m))\n\u001b[0;32m      2\u001b[0m tensor_gen \u001b[39m=\u001b[39m generate_tensor(data, \u001b[39m1500\u001b[39m, \u001b[39m3200\u001b[39m, sliding_window_size\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m arr_to_add \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(\u001b[39mnext\u001b[39;49m(tensor_gen), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m test_arr \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mconcatenate((test_arr,  arr_to_add), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m      5\u001b[0m test_arr\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test_arr = np.empty((0,10,150,320))\n",
    "tensor_gen = generate_tensor(data, 1500, 3200, sliding_window_size=10)\n",
    "arr_to_add = np.expand_dims(next(tensor_gen), axis=0)\n",
    "test_arr = np.concatenate((test_arr,  arr_to_add), axis=0)\n",
    "test_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# path = \"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/data_augmentation/data_four_labels_augmentation\"\n",
    "path = \"C:/Users/malik/Desktop/ASL-Aly/ASL-words-translator/data_augmentation/data_four_labels_augmentation\"\n",
    "def find_max_dim__for_entire_folder(path, sliding_window_size = 10):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    max_x_dim = 0\n",
    "    max_y_dim = 0\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%4 == 0:\n",
    "                    data = read_csv(os.path.join(path, label, file))\n",
    "                    max_x = find_max_for_one_file(data, \"x\") * 1000\n",
    "                    max_y = find_max_for_one_file(data, \"y\") * 1000\n",
    "                    x_dim = round(math.ceil(max_x/100)*100, -1)\n",
    "                    y_dim = round(math.ceil(max_y/100)*100, -1)\n",
    "                    if max_x_dim < x_dim:\n",
    "                        max_x_dim = x_dim\n",
    "                    if max_y_dim < y_dim:\n",
    "                        max_y_dim = y_dim\n",
    "                i += 1\n",
    "        print(label, max_x_dim, max_y_dim)\n",
    "    return max_x_dim, max_y_dim\n",
    "# find_max_dim__for_entire_folder(path, sliding_window_size = 10)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 100 coffee ax2UGtA8h3E2137_reflection.csv\n",
      "2 200 coffee blZ0jXHGbYI0_reflection_rotation_15.csv_projective_geo_13_True.csv\n",
      "3 300 coffee c0tloO5tJUY7125_reflection_rotation_15_scale_0.2.csv_projective_geo_7_False.csv\n",
      "4 300 coffee c0tloO5tJUY7125_reflection_rotation_15_scale_0.2_translate_0.5_left.csv\n",
      "5 400 coffee c0tloO5tJUY7209_reflection_rotation_15_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "6 500 coffee CSj7IScvZnE5770_reflection_rotation_15_translation_0.5.csv_projective_geo_8_False.csv\n",
      "7 600 coffee CxTSVyM-ij013680_reflection_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv\n",
      "8 700 coffee CxTSVyM-ij013790_reflection_rotation_15_translation_0.5_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "9 800 coffee eeHS78JyN706789_reflection_scale_0.2.csv_projective_geo_10_True.csv\n",
      "10 900 coffee eeHS78JyN706909_reflection_translate_0.5_left.csv\n",
      "11 1000 coffee FEZ2sZmYRbI0_reflection_translation_0.5.csv_projective_geo_11_False.csv\n",
      "12 1100 coffee fKjsdtMU3fc8470_reflection_translation_0.5_scale_0.2.csv_projective_geo_7_True.csv\n",
      "13 1200 coffee FNt4N8WFuVY15740_reflection_translation_0.5_translate_0.5_left.csv\n",
      "14 1300 coffee FNt4N8WFuVY15970_rotation_15.csv_projective_geo_14_True.csv\n",
      "15 1400 coffee FUHOIo_8o9w4459_rotation_15_scale_0.2.csv_projective_geo_13_False.csv\n",
      "16 1500 coffee hUrfB8bikfw1380_rotation_15_translate_0.5_left.csv\n",
      "17 1600 coffee hUrfB8bikfw1437_rotation_15_translation_0.5.csv_projective_geo_11_False.csv\n",
      "18 1700 coffee jzemBg_G8zU4505_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_9_True.csv\n",
      "19 1800 coffee jzemBg_G8zU4637_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "20 1900 coffee KFSLtsOwZiU1121_scale_0.2.csv_projective_geo_14_False.csv\n",
      "21 2000 coffee mCjHYreiZ2417341_scale_0.2_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "22 2100 coffee MIPvaUKFA4c303_translation_0.5.csv\n",
      "23 2200 coffee n0PdKty8WRA2084_translation_0.5_scale_0.2.csv_projective_geo_12_False.csv\n",
      "24 2300 coffee nHnqAu_1K-c3396_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_9_True.csv\n",
      "25 2400 coffee Rz2NwFuHic80.csv\n",
      "26 2500 coffee sErq0TJMKEo4730_reflection.csv_projective_geo_10_False.csv\n",
      "27 2500 coffee sErq0TJMKEo4730_reflection.csv_projective_geo_12_True.csv\n",
      "28 2500 coffee sErq0TJMKEo4730_reflection_rotation_15.csv\n",
      "29 2600 coffee uVLwe5c7LaQ0_reflection_rotation_15_scale_0.2.csv_projective_geo_6_False.csv\n",
      "30 2700 coffee vcB472PRkJM0_reflection_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_9_False.csv\n",
      "31 2800 coffee vE4RFGPqGqY5721_reflection_rotation_15_translation_0.5.csv\n",
      "32 2900 coffee _wijo648v0g3208_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_10_True.csv\n",
      "1 100 dog 3m1X5NYCA_I238_reflection.csv\n",
      "2 200 dog 498gWK7nFCI20_reflection_rotation_15.csv_projective_geo_8_False.csv\n",
      "3 300 dog Ag5VPvAe8PA5557_reflection_rotation_15_scale_0.2.csv_projective_geo_8_True.csv\n",
      "4 400 dog catBjk1p2bk0_reflection_rotation_15_translate_0.5_left.csv\n",
      "5 500 dog E3ILIbZqcKY3566_reflection_rotation_15_translation_0.5.csv_projective_geo_12_False.csv\n",
      "6 600 dog FBD4NFz4QaA4056_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_13_False.csv\n",
      "7 700 dog FNt4N8WFuVY10641_reflection_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "8 800 dog FNt4N8WFuVY10731_reflection_scale_0.2.csv_projective_geo_13_True.csv\n",
      "9 900 dog g59_3vr_NT01632_reflection_scale_0.2_translate_0.5_left.csv_projective_geo_5_True.csv\n",
      "10 1000 dog H3jZwwuYOQA2915_reflection_translation_0.5.csv\n",
      "11 1100 dog H3jZwwuYOQA2995_reflection_translation_0.5_scale_0.2.csv_projective_geo_5_True.csv\n",
      "12 1200 dog IbpJtH_QssM0_reflection_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "13 1300 dog KRrKqGEGdMg18884_rotation_15.csv\n",
      "14 1400 dog KsvdFnvMNAA5553_rotation_15_scale_0.2.csv_projective_geo_5_True.csv\n",
      "15 1500 dog LHQW0IYz7pI0_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_13_True.csv\n",
      "16 1600 dog lvqGMGFmuV4325_rotation_15_translation_0.5.csv\n",
      "17 1700 dog N5ZUQxL4__c0_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_12_True.csv\n",
      "18 1800 dog ohjlMkxe1Wc1671_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_6_True.csv\n",
      "19 1900 dog ohjlMkxe1Wc1731_scale_0.2.csv\n",
      "20 2000 dog ohjlMkxe1Wc1831_scale_0.2_translate_0.5_left.csv_projective_geo_5_True.csv\n",
      "21 2100 dog Ou-7SRWs0e0128_translate_0.5_left.csv_projective_geo_14_False.csv\n",
      "22 2200 dog Ou-7SRWs0e0308_translation_0.5_scale_0.2.csv\n",
      "23 2300 dog Ou-7SRWs0e041_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "24 2400 dog pl2FLu62aSA421_translation_0.5_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "25 2500 dog R_ES8RZua1g11082_reflection.csv\n",
      "26 2600 dog R_ES8RZua1g11185_reflection_rotation_15.csv_projective_geo_11_False.csv\n",
      "27 2700 dog SJAhRxI7i9c1026_reflection_rotation_15_scale_0.2.csv_projective_geo_14_False.csv\n",
      "28 2800 dog sUC-XDC5TvA2228_reflection_rotation_15_translate_0.5_left.csv\n",
      "29 2900 dog sUC-XDC5TvA2368_reflection_rotation_15_translation_0.5.csv_projective_geo_11_True.csv\n",
      "30 3000 dog sUC-XDC5TvA2418_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_7_True.csv\n",
      "31 3100 dog TXmuXH4fmu00_reflection_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "32 3200 dog UXetwN_cI5A8984_reflection_scale_0.2.csv_projective_geo_7_True.csv\n",
      "33 3300 dog UXetwN_cI5A9114_reflection_scale_0.2_translate_0.5_left.csv_projective_geo_7_False.csv\n",
      "34 3400 dog zdUALCKtOOk0_reflection_translation_0.5.csv\n",
      "1 100 door 0bIF7jh6lnE4677_reflection.csv\n",
      "2 200 door 2VB3WN8adyM7255_reflection_rotation_15.csv_projective_geo_14_True.csv\n",
      "3 300 door A0TTA7Rlkzc1947_reflection_rotation_15_scale_0.2.csv_projective_geo_5_True.csv\n",
      "4 400 door A0TTA7Rlkzc2027_reflection_rotation_15_translate_0.5_left.csv\n",
      "5 500 door eMZdggjnLQA5067_reflection_rotation_15_translation_0.5.csv_projective_geo_12_False.csv\n",
      "6 600 door fNg_sJ9f8EI13768_reflection_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_5_True.csv\n",
      "7 700 door Ip1L7UrulFE0_reflection_rotation_15_translation_0.5_translate_0.5_left.csv\n",
      "8 800 door iWJgaNo9Z041756_reflection_scale_0.2.csv_projective_geo_10_True.csv\n",
      "9 900 door j8a5Z-5lUwo598_reflection_scale_0.2_translate_0.5_left.csv_projective_geo_13_False.csv\n",
      "10 1000 door j8a5Z-5lUwo679_reflection_translation_0.5.csv\n",
      "11 1100 door K4lo0NZDlH86823_reflection_translation_0.5_scale_0.2.csv_projective_geo_12_True.csv\n",
      "12 1200 door nHnqAu_1K-c12221_reflection_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_8_False.csv\n",
      "13 1300 door nHnqAu_1K-c12581_rotation_15.csv\n",
      "14 1400 door nHnqAu_1K-c12667_rotation_15_scale_0.2.csv_projective_geo_12_False.csv\n",
      "15 1500 door RAtOGNDP0dg3834_rotation_15_scale_0.2_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "16 1600 door RAtOGNDP0dg3854_rotation_15_translation_0.5.csv\n",
      "17 1700 door rnr_aY0X0dQ5683_rotation_15_translation_0.5_scale_0.2.csv_projective_geo_7_False.csv\n",
      "18 1800 door SiTBL7DYzZQ1382_rotation_15_translation_0.5_scale_0.2_translate_0.5_left.csv_projective_geo_14_True.csv\n",
      "19 1900 door tO6x4rdDNXk5265_scale_0.2.csv\n",
      "20 2000 door tO6x4rdDNXk5375_scale_0.2_translate_0.5_left.csv_projective_geo_14_False.csv\n",
      "21 2100 door UjiCWH8PSvM832_translate_0.5_left.csv_projective_geo_9_False.csv\n",
      "22 2200 door WCGDN5CniTY0_translation_0.5_scale_0.2.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[32], line 40\u001b[0m\n\u001b[0;32m     38\u001b[0m                            y_train\u001b[39m.\u001b[39mappend(label)\n\u001b[0;32m     39\u001b[0m                i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m---> 40\u001b[0m process_entire_folder(path, sliding_window_size, x_dim, y_dim)\n",
      "Cell \u001b[1;32mIn[32], line 30\u001b[0m, in \u001b[0;36mprocess_entire_folder\u001b[1;34m(path, sliding_window_size, x_dim, y_dim)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m     29\u001b[0m tensor_generator \u001b[39m=\u001b[39m generate_tensor(data, x_dim, y_dim, sliding_window_size)\n\u001b[1;32m---> 30\u001b[0m \u001b[39mfor\u001b[39;00m tensor \u001b[39min\u001b[39;00m tensor_generator:\n\u001b[0;32m     31\u001b[0m     arr_to_add \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexpand_dims(tensor, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m j\u001b[39m%\u001b[39m\u001b[39m5\u001b[39m \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     33\u001b[0m         \u001b[39m# add to validation set\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mgenerate_tensor\u001b[1;34m(data, x_dim, y_dim, sliding_window_size)\u001b[0m\n\u001b[0;32m      6\u001b[0m tensor \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros((sliding_window_size, x_dim\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m,y_dim\u001b[39m/\u001b[39m\u001b[39m/\u001b[39m\u001b[39m10\u001b[39m))\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i, i \u001b[39m+\u001b[39m \u001b[39m10\u001b[39m):\n\u001b[1;32m----> 8\u001b[0m     new_matrix \u001b[39m=\u001b[39m initialize_matrix_for_frame(data, j, x_dim, y_dim)\n\u001b[0;32m      9\u001b[0m     tensor[j\u001b[39m-\u001b[39mi] \u001b[39m=\u001b[39m new_matrix\n\u001b[0;32m     10\u001b[0m \u001b[39myield\u001b[39;00m tensor\n",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m, in \u001b[0;36minitialize_matrix_for_frame\u001b[1;34m(data, idx, x_dim, y_dim)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize_matrix_for_frame\u001b[39m(data, idx, x_dim, y_dim):\n\u001b[0;32m      2\u001b[0m    \n\u001b[0;32m      3\u001b[0m     \u001b[39m# create a matrix of all zeros\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mzeros((x_dim\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m10\u001b[39;49m,y_dim\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m10\u001b[39;49m))\n\u001b[0;32m      5\u001b[0m     \u001b[39m# fill the matrix with random values\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     frame \u001b[39m=\u001b[39m data[idx]\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # 80/20 split\n",
    "x_dim = 1500\n",
    "y_dim = 3200\n",
    "sliding_window_size = 10\n",
    "\n",
    "def process_entire_folder(path, sliding_window_size = 10, x_dim=1500, y_dim=3200):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_val\n",
    "    global y_val\n",
    "    X_train = np.empty((0,10,x_dim//10,y_dim//10))\n",
    "    y_train = []\n",
    "    X_val = np.empty((0,10,x_dim//10,y_dim//10))\n",
    "    y_val = []\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%100 == 0:\n",
    "                    j += 1\n",
    "                    print(j, i, label, file)\n",
    "                    file_path = os.path.join(path, label, file)\n",
    "                    data = read_csv(file_path)\n",
    "                    if np.isnan(data).any():\n",
    "                        continue\n",
    "                    tensor_generator = generate_tensor(data, x_dim, y_dim, sliding_window_size)\n",
    "                    for tensor in tensor_generator:\n",
    "                        arr_to_add = np.expand_dims(tensor, axis=0)\n",
    "                        if j%5 == 0:\n",
    "                            # add to validation set\n",
    "                            X_val = np.concatenate((X_val,  arr_to_add), axis=0)\n",
    "                            y_val.append(label)\n",
    "                        else:\n",
    "                            X_train = np.concatenate((X_train,  arr_to_add), axis=0)\n",
    "                            y_train.append(label)\n",
    "                i += 1\n",
    "process_entire_folder(path, sliding_window_size, x_dim, y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10, 150, 320)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 10, 150, 320)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1000 dog g59_3vr_NT01632_translate_0.5_left.csv_projective_geo_7_True.csv\n",
      "2 2000 dog rIlQQTN2b586887_reflection_rotation_15_translation_0.5_scale_0.2.csv\n",
      "3 3000 dog sUC-XDC5TvA2228_reflection_rotation_15.csv_projective_geo_9_True.csv\n",
      "1 1000 milk jDCw7stJaM43664_reflection_translation_0.5.csv_projective_geo_14_True.csv\n",
      "2 2000 milk wjbWyQLPqwQ0_translation_0.5.csv_projective_geo_6_True.csv\n",
      "3 3000 milk MIPvaUKFA4c750_reflection_translation_0.5_translate_0.5_left.csv\n",
      "4 4000 milk 6UrcyZ-QeiU550_scale_0.2.csv_projective_geo_7_False.csv\n",
      "1 1000 coffee eeHS78JyN706909_rotation_15_translate_0.5_left.csv\n",
      "2 2000 coffee FUHOIo_8o9w4459_translation_0.5.csv\n",
      "1 1000 door nHnqAu_1K-c12221_reflection_translation_0.5.csv_projective_geo_12_True.csv\n",
      "2 2000 door K4lo0NZDlH86823_scale_0.2_translate_0.5_left.csv\n"
     ]
    }
   ],
   "source": [
    "x_dim = 1500\n",
    "y_dim = 3200\n",
    "sliding_window_size = 10\n",
    "\n",
    "def process_entire_folder(path, sliding_window_size = 10, x_dim=1500, y_dim=3200):\n",
    "    # The first thing to do is find the maximum x and y values for our matrices\n",
    "    global X_train\n",
    "    global y_train\n",
    "    global X_val\n",
    "    global y_val\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_val = []\n",
    "    y_val = []\n",
    "    for label in os.listdir(path):\n",
    "        if label != \".DS_Store\":\n",
    "            i = 1\n",
    "            j = 0\n",
    "            for file in os.listdir(os.path.join(path, label)):\n",
    "                # pick 25% of the data\n",
    "                if i%1000 == 0:\n",
    "                    j += 1\n",
    "                    print(j, i, label, file)\n",
    "                    tensor_generator = generate_tensor(data, x_dim, y_dim, sliding_window_size)\n",
    "                    for tensor in tensor_generator:\n",
    "                        \n",
    "                        if j%5 == 0:\n",
    "                            # add to validation set\n",
    "                            X_val.append(tensor)\n",
    "                            y_val.append(label)\n",
    "                        else:\n",
    "                            X_train.append(tensor)\n",
    "                            y_train.append(label)\n",
    "                i += 1\n",
    "process_entire_folder(path, sliding_window_size, x_dim, y_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_label(label_arr):    \n",
    "#should be between 0 and 3\n",
    "    dicti={\"coffee\": 0, \"dog\": 1, \"door\": 2, \"milk\": 3}\n",
    "    # for element in df_labels:\n",
    "    #     element = dicti[element]\n",
    "    for i in range(len(label_arr)):\n",
    "        label_arr[i] = dicti[label_arr[i]]\n",
    "    return label_arr\n",
    "y_train = reformat_label(y_train)\n",
    "y_val = reformat_label(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]],\n",
       " \n",
       " \n",
       "        [[[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]],\n",
       " \n",
       "         [[74.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          ...,\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
       "          [ 0.,  0.,  0., ...,  0.,  0.,  0.]]]]),\n",
       " [2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  1,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  1,\n",
       "  3,\n",
       "  3,\n",
       "  2,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  1,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  2,\n",
       "  3,\n",
       "  2,\n",
       "  1,\n",
       "  3,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train,Y_train = shuffle(X_train, y_train, random_state=0)\n",
    "X_val,Y_val = shuffle(X_val, y_val, random_state=0)\n",
    "X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(770, 1) (175, 1)\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(Y_train).reshape((-1, 1))\n",
    "Y_val = np.array(Y_val).reshape((-1, 1))\n",
    "print(Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/training_models/mediapipe/Sliding_window_dense-Layers/AUGMENTED-CNN.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv3d_5 (Conv3D)           (None, 8, 148, 318, 32)   896       \n",
      "                                                                 \n",
      " max_pooling3d_4 (MaxPooling  (None, 2, 2, 2, 32)      0         \n",
      " 3D)                                                             \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 2, 2, 2, 32)       0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 4)                 516       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 100,100\n",
      "Trainable params: 100,100\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(layers.Conv3D(32,(3,3,3),activation='relu',input_shape=(10, 150, 320, 1)))\n",
    "model.add(layers.MaxPooling3D((5, 75, 160), padding=\"same\"))\n",
    "# model.add(layers.Conv3D(64,(2,2,2),activation='relu'))\n",
    "# model.add(layers.MaxPooling3D((2, 38, 80), padding=\"same\"))\n",
    "model.add(layers.Dropout(0.6))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(256,'relu'))\n",
    "model.add(layers.Dense(128,'relu'))\n",
    "# model.add(layers.Dropout(0.5))\n",
    "# model.add(layers.Dense(128,'relu'))\n",
    "# model.add(layers.Dense(64,'relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(4,'softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['accuracy'],\n",
    "             )\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'MaxPool3D' used by {{node sequential_5/max_pooling3d_4/MaxPool3D}} with these attrs: [ksize=[1, 5, 75, 160, 1], padding=\"SAME\", T=DT_HALF, strides=[1, 5, 75, 160, 1], data_format=\"NDHWC\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_BFLOAT16, DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n\n\t [[sequential_5/max_pooling3d_4/MaxPool3D]] [Op:__inference_train_function_3726]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Fit data to model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(X_train, Y_train,\n\u001b[1;32m      3\u001b[0m             batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m,\n\u001b[1;32m      4\u001b[0m             epochs\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m             validation_data\u001b[39m=\u001b[39;49m(X_val,Y_val), callbacks\u001b[39m=\u001b[39;49m[checkpoint])\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/asl-converter/lib/python3.8/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/opt/miniconda3/envs/asl-converter/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'MaxPool3D' used by {{node sequential_5/max_pooling3d_4/MaxPool3D}} with these attrs: [ksize=[1, 5, 75, 160, 1], padding=\"SAME\", T=DT_HALF, strides=[1, 5, 75, 160, 1], data_format=\"NDHWC\"]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_BFLOAT16, DT_HALF]\n  device='CPU'; T in [DT_FLOAT]\n\n\t [[sequential_5/max_pooling3d_4/MaxPool3D]] [Op:__inference_train_function_3726]"
     ]
    }
   ],
   "source": [
    "# Fit data to model\n",
    "history = model.fit(X_train, Y_train,\n",
    "            batch_size=32,\n",
    "            epochs=40,\n",
    "            verbose=1,\n",
    "            validation_data=(X_val,Y_val), callbacks=[checkpoint])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl-converter",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
