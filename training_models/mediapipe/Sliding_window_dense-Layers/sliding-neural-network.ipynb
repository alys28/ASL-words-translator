{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras import Sequential\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class        x1        y1        z1        v1        x2        y2  \\\n",
      "0    coffee  0.490560  0.290803 -0.457349  0.999989  0.507861  0.251743   \n",
      "1    coffee  0.490317  0.296208 -0.467214  0.999987  0.507768  0.253555   \n",
      "2    coffee  0.490271  0.300322 -0.470750  0.999986  0.507730  0.255209   \n",
      "3    coffee  0.490268  0.302454 -0.487628  0.999985  0.507728  0.256161   \n",
      "4    coffee  0.490803  0.303688 -0.505418  0.999985  0.507995  0.256749   \n",
      "..      ...       ...       ...       ...       ...       ...       ...   \n",
      "110  coffee  0.496863  0.302861 -0.649061  0.999965  0.513863  0.255302   \n",
      "111  coffee  0.496631  0.301382 -0.643764  0.999955  0.513532  0.254744   \n",
      "112  coffee  0.496510  0.300023 -0.687388  0.999919  0.513147  0.254390   \n",
      "113  coffee  0.496565  0.299678 -0.744448  0.999876  0.513067  0.254359   \n",
      "114  coffee  0.496665  0.299629 -0.655965  0.999852  0.513007  0.254376   \n",
      "\n",
      "           z2        v2        x3  ...       z73  v73       x74       y74  \\\n",
      "0   -0.412709  0.999987  0.516950  ... -0.039968  0.0  0.496138  0.838479   \n",
      "1   -0.425430  0.999984  0.516758  ... -0.032240  0.0  0.499593  0.842492   \n",
      "2   -0.429952  0.999982  0.516656  ... -0.032046  0.0  0.501178  0.847488   \n",
      "3   -0.446110  0.999981  0.516634  ... -0.032033  0.0  0.500290  0.853992   \n",
      "4   -0.462483  0.999980  0.516718  ... -0.031262  0.0  0.500826  0.858976   \n",
      "..        ...       ...       ...  ...       ...  ...       ...       ...   \n",
      "110 -0.599471  0.999905  0.523044  ...  0.000000  0.0  0.000000  0.000000   \n",
      "111 -0.594247  0.999894  0.522931  ...  0.000000  0.0  0.000000  0.000000   \n",
      "112 -0.633070  0.999848  0.522765  ...  0.000000  0.0  0.000000  0.000000   \n",
      "113 -0.690254  0.999778  0.522710  ...  0.000000  0.0  0.000000  0.000000   \n",
      "114 -0.606255  0.999730  0.522649  ...  0.000000  0.0  0.000000  0.000000   \n",
      "\n",
      "          z74  v74       x75       y75       z75  v75  \n",
      "0   -0.032200  0.0  0.510814  0.841485 -0.026400  0.0  \n",
      "1   -0.023976  0.0  0.513295  0.845279 -0.018187  0.0  \n",
      "2   -0.023551  0.0  0.515599  0.849821 -0.017611  0.0  \n",
      "3   -0.023843  0.0  0.514286  0.856211 -0.018308  0.0  \n",
      "4   -0.022877  0.0  0.514729  0.861247 -0.017345  0.0  \n",
      "..        ...  ...       ...       ...       ...  ...  \n",
      "110  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "111  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "112  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "113  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "114  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "\n",
      "[115 rows x 301 columns]\n"
     ]
    }
   ],
   "source": [
    "#import the data ---> these lines are just testing.\n",
    "test = pd.read_csv(\"../Database-augmented/coffee/_wijo648v0g3208.csv\")\n",
    "print(test)\n",
    "\n",
    "# test2=pd.read_csv(\"data_four_labels/coffee/2sGQuduhAf41354.csv\")\n",
    "# print(test2)\n",
    "\n",
    "# final_df=pd.concat([test,test2])\n",
    "# print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9776, 301) (3667, 301)\n",
      "training set:\n",
      "     class        x1        y1        z1        v1        x2        y2  \\\n",
      "0   coffee  0.606142  0.244242 -0.815652  0.999938  0.623723  0.211371   \n",
      "1   coffee  0.606009  0.244254 -0.815749  0.999938  0.623691  0.211367   \n",
      "2   coffee  0.605101  0.244437 -0.754448  0.999933  0.623574  0.211543   \n",
      "3   coffee  0.602850  0.244439 -0.760619  0.999929  0.622494  0.211495   \n",
      "4   coffee  0.602109  0.244449 -0.827007  0.999929  0.622169  0.211413   \n",
      "..     ...       ...       ...       ...       ...       ...       ...   \n",
      "75    milk  0.497894  0.306149 -0.517604  0.999934  0.515566  0.259491   \n",
      "76    milk  0.497847  0.305891 -0.508041  0.999933  0.515531  0.259391   \n",
      "77    milk  0.497788  0.305599 -0.499464  0.999932  0.515466  0.259253   \n",
      "78    milk  0.497708  0.305279 -0.495048  0.999933  0.515386  0.259108   \n",
      "79    milk  0.497436  0.305055 -0.492145  0.999933  0.515184  0.258973   \n",
      "\n",
      "          z2        v2        x3  ...       z73  v73       x74       y74  \\\n",
      "0  -0.776338  0.999922  0.634001  ... -0.036408  0.0  0.659736  0.707858   \n",
      "1  -0.775937  0.999923  0.633704  ... -0.031901  0.0  0.660784  0.701760   \n",
      "2  -0.711242  0.999918  0.633406  ... -0.031837  0.0  0.664421  0.694444   \n",
      "3  -0.722415  0.999914  0.632134  ... -0.033219  0.0  0.666726  0.688564   \n",
      "4  -0.783732  0.999915  0.631638  ... -0.035322  0.0  0.662254  0.690637   \n",
      "..       ...       ...       ...  ...       ...  ...       ...       ...   \n",
      "75 -0.484481  0.999870  0.526420  ...  0.000000  0.0  0.000000  0.000000   \n",
      "76 -0.473689  0.999870  0.526399  ...  0.000000  0.0  0.000000  0.000000   \n",
      "77 -0.464760  0.999870  0.526358  ...  0.000000  0.0  0.000000  0.000000   \n",
      "78 -0.460512  0.999872  0.526302  ...  0.000000  0.0  0.000000  0.000000   \n",
      "79 -0.458362  0.999873  0.526164  ...  0.000000  0.0  0.000000  0.000000   \n",
      "\n",
      "         z74  v74       x75       y75       z75  v75  \n",
      "0  -0.029399  0.0  0.671787  0.705231 -0.024129  0.0  \n",
      "1  -0.027481  0.0  0.672509  0.700027 -0.023272  0.0  \n",
      "2  -0.027150  0.0  0.676313  0.692712 -0.022846  0.0  \n",
      "3  -0.028706  0.0  0.678016  0.686593 -0.024647  0.0  \n",
      "4  -0.030620  0.0  0.674081  0.689211 -0.026338  0.0  \n",
      "..       ...  ...       ...       ...       ...  ...  \n",
      "75  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "76  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "77  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "78  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "79  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
      "\n",
      "[9776 rows x 301 columns]\n",
      "testing set: \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "names = [\"coffee\", \"dog\", \"door\", \"milk\"]\n",
    "i = 0\n",
    "for label in names:\n",
    "    files = glob.glob(f\"data_four_labels/{label}/*.csv\")\n",
    "    # files = glob.glob(f\"../Database-augmented/{label}/*.csv\")\n",
    "    for f in files:\n",
    "        csv = pd.read_csv(f)\n",
    "\n",
    "    #this is in order to separate the training set from the test set (setting 25% of values\n",
    "        if i%4:    \n",
    "            train_df = pd.concat([train_df, csv])\n",
    "        else:\n",
    "            test_df = pd.concat([test_df, csv])\n",
    "        i += 1\n",
    "        train_df.head\n",
    "\n",
    "print(train_df.shape, test_df.shape)\n",
    "print(\"training set:\")\n",
    "print(train_df)\n",
    "print(\"testing set: \")\n",
    "# test_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since I am working on varying time frames, I will be concatenating the data into sets of n-frames together as one datapoint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ok, use lists next time, and then transform into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header(FrameNumber, className):\n",
    "    #at first, only one element, the class name\n",
    "    headerList=[className]\n",
    "    for i in range(FrameNumber):\n",
    "        for val in range(1, num_coords+1):        \n",
    "            headerList += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
    "            all_frames = all_frames.reshape((len(df), 75, 4))\n",
    "    print(headerList)\n",
    "    return headerList\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_label(df, FrameNumber):\n",
    "    #its the same label for each video\n",
    "    label = df[\"class\"].iloc[0]\n",
    "    # labels = df[\"class\"].values.tolist()\n",
    "    # labels = labels[FrameNumber:len(labels)]\n",
    "    return label\n",
    "\n",
    "def create_data(video, labels_dict, window_size=20): #video format: (#frames, 75, 4)\n",
    "    labels = video[\"class\"].iloc[0]\n",
    "    print(labels)\n",
    "    label = labels_dict[labels]\n",
    "\n",
    "    video.drop(columns=df.columns[0], axis=1, inplace = True)\n",
    "    \n",
    "    # dfList = video.values.tolist()\n",
    "    dfList = video.to_numpy().reshape((len(video), 75, 4)).tolist()\n",
    "    # type(dfList)\n",
    "\n",
    "    \n",
    "    finalLabels = [[label]]\n",
    "    data = []\n",
    "    temp = dfList[0: window_size]\n",
    "    # print(temp[19])\n",
    "    # print(type(temp))\n",
    "    data.append(temp)\n",
    "\n",
    "    for i in range(window_size, len(video)):\n",
    "        # print(type(temp))\n",
    "        \n",
    "        temp.pop(0)\n",
    "        # print(type(temp))\n",
    "        temp.append(dfList[i])\n",
    "        # print(type(temp))\n",
    "        # print(\"df list:\",type(dfList))\n",
    "        finalLabels.append([label])\n",
    "        data.append(temp)\n",
    "\n",
    "    return np.array(data), labels\n",
    "\n",
    "\n",
    "#past code, the code on top does the same\n",
    "    # def first_continuity(df, FrameNumber):\n",
    "    #     ls = df.iloc[i:i+FrameNumber].values.tolist()\n",
    "    #     return ls\n",
    "\n",
    "    # def modify_continuity(tmp_ls, next_row):\n",
    "    #     tmp_ls.append(next_row)\n",
    "    #     tmp_ls.pop(0)\n",
    "    #     return tmp_ls\n",
    "\n",
    "    # def time_continuity(df, FrameNumber):\n",
    "    #     finalList = []\n",
    "\n",
    "    #     labels, df = get_label(df, FrameNumber)\n",
    "        \n",
    "    #     tmp_list = first_continuity(df, FrameNumber)\n",
    "    #     finaList.append(tmp_list)\n",
    "\n",
    "    #     dataList = df.values.tolist()\n",
    "    #     print(\"The number of labels is \", len(labels))\n",
    "    #     size = len(dataList-FrameNumber)\n",
    "    #     print(\"The number of datapoints is \" , size)\n",
    "\n",
    "    #     for i in range(FrameNumber, len(dataList)-1):\n",
    "    #         tmp_list = modify_continuity(tmp_list, dataList[i])\n",
    "    #         finalList.append(tmp_list)\n",
    "\n",
    "    #     return finalList\n",
    "\n",
    "#---- SARINA, uncomment DOWN HERE------#\n",
    "    #-------------------------------------------\n",
    "    # label = df[0].iloc[0]\n",
    "    # print(\"HI\")\n",
    "    # previous_frames = [label]\n",
    "    # #saving the first n frames:\n",
    "    # headerList = header(FrameNumber, label)\n",
    "    # new_df = pd.DataFrame(columns = headerList)\n",
    "    \n",
    "    # for row in range(FrameNumber):\n",
    "    #     i=0\n",
    "    #     for el in row:\n",
    "    #         if i==0:\n",
    "    #             i+=1\n",
    "    #             continue\n",
    "    #         previous_frames.append(df[el].iloc[row])\n",
    "        \n",
    "    # for row in range(FrameNumber, len(df)):\n",
    "    #     new_df.concat(previous_frames)\n",
    "    #     #removing the first n elements.\n",
    "    #     previous_frames = previous_frames[len(headerList):]\n",
    "    #     previous_frames.push_front(label)\n",
    "\n",
    "    #     i=0\n",
    "    #     for el in row:\n",
    "    #         if i==0:\n",
    "    #             #skip the class name\n",
    "    #             i+=1\n",
    "    #             continue\n",
    "    #         previous_frames.append(df[el].iloc[row])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "door\n",
      "[[[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.03555595 -0.4384019  -0.50958222  0.99958414]\n",
      "   [-0.05698883 -0.47199654 -0.47453678  0.99920177]\n",
      "   [-0.06581765 -0.47184452 -0.47429746  0.99942136]\n",
      "   ...\n",
      "   [-0.04346167 -0.01287028 -0.0310615   0.        ]\n",
      "   [-0.0333653   0.00835261 -0.03215871  0.        ]\n",
      "   [-0.02910929  0.02609668 -0.03201184  0.        ]]\n",
      "\n",
      "  [[-0.0367224  -0.43818782 -0.49445817  0.99958211]\n",
      "   [-0.05796853 -0.47181041 -0.45664948  0.99919307]\n",
      "   [-0.06675116 -0.47165538 -0.45638946  0.99941379]\n",
      "   ...\n",
      "   [-0.0451797  -0.01185767 -0.03042152  0.        ]\n",
      "   [-0.03509317  0.00925441 -0.03176541  0.        ]\n",
      "   [-0.03058992  0.02731104 -0.0317043   0.        ]]\n",
      "\n",
      "  [[-0.03662299 -0.43854078 -0.48717502  0.99958056]\n",
      "   [-0.05771803 -0.47236657 -0.44781321  0.99918425]\n",
      "   [-0.06631499 -0.47221622 -0.44755417  0.99940807]\n",
      "   ...\n",
      "   [-0.04654132 -0.00898412 -0.02980233  0.        ]\n",
      "   [-0.03635829  0.01254353 -0.03101698  0.        ]\n",
      "   [-0.03169583  0.03035107 -0.03045327  0.        ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[-0.14512429 -0.30629183 -0.54620785  0.99960375]\n",
      "   [-0.16795829 -0.34082846 -0.50780237  0.99906766]\n",
      "   [-0.18108216 -0.33894325 -0.50751096  0.9992786 ]\n",
      "   ...\n",
      "   [-0.20559881  0.23320218 -0.02020204  0.        ]\n",
      "   [-0.19895992  0.2386501  -0.01749844  0.        ]\n",
      "   [-0.19578991  0.24280216 -0.01551743  0.        ]]\n",
      "\n",
      "  [[-0.14444581 -0.30448236 -0.53216928  0.99960387]\n",
      "   [-0.16779348 -0.33953892 -0.4947311   0.99905771]\n",
      "   [-0.18090585 -0.33708184 -0.49442399  0.99926931]\n",
      "   ...\n",
      "   [-0.2015731   0.23095877 -0.0213305   0.        ]\n",
      "   [-0.19204161  0.23480369 -0.01884264  0.        ]\n",
      "   [-0.1858916   0.23708195 -0.01672599  0.        ]]\n",
      "\n",
      "  [[-0.1414355  -0.29796131 -0.53943002  0.99959975]\n",
      "   [-0.16530716 -0.3345347  -0.50248861  0.99904436]\n",
      "   [-0.17828529 -0.33198588 -0.50215393  0.99925548]\n",
      "   ...\n",
      "   [-0.19818502  0.23274616 -0.02297057  0.        ]\n",
      "   [-0.19275283  0.2373294  -0.02064425  0.        ]\n",
      "   [-0.19010978  0.24056057 -0.01845843  0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"test-file.csv\")\n",
    "dfList = df.values.tolist()\n",
    "dicti={\"coffee\": 0, \"dog\": 1, \"door\": 2, \"milk\": 3}\n",
    "npData, labels = create_data(video = df, labels_dict = dicti, window_size=20 )\n",
    "# all_frames = df.to_numpy().reshape((len(df), 75, 4))\n",
    "\n",
    "# finalList = time_continuity(df, 10)\n",
    "# # print(finalList)\n",
    "# # type(finalList)\n",
    "# print(len(finalList), len(finalList[0]), len(finalList[0][0]))\n",
    "# # df.head()\n",
    "# # df.head(100)\n",
    "print(npData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameNumber = 10\n",
    "time_continuity(train_df, FrameNumber = 2)\n",
    "time_continuity(test_df, FrameNumber = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### separating the features from the labels (just some testing, not actually used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_label(df):\n",
    "    df_features = df.copy()\n",
    "\n",
    "    df_labels = df_features.pop(\"class\")\n",
    "\n",
    "    df_features = np.array(df_features)\n",
    "    # df_labels = np.array(df_labels)\n",
    "    print(df_features.shape)\n",
    "    print(df_labels.shape, type(df_labels))\n",
    "    return df_features, df_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train = seperate_label(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val, Y_val = seperate_label(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
    "#           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
    "#           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
    "# df = pd.DataFrame(mydict)\n",
    "# print(df.head())\n",
    "# mylist = []\n",
    "# mylist.append(df.iloc[1])\n",
    "# for i in mylist:\n",
    "#     print(i)\n",
    "#     # for l in i:\n",
    "#     #     print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I\"ll also remap every string to an int\n",
    "per example, \n",
    "through a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformat_label(df_labels):    \n",
    "#should be between 0 and 3\n",
    "    dicti={\"coffee\": 0, \"dog\": 1, \"door\": 2, \"milk\": 3}\n",
    "    # for element in df_labels:\n",
    "    #     element = dicti[element]\n",
    "\n",
    "    def change_label(x):\n",
    "        return dicti[x]\n",
    "\n",
    "    df_labels = df_labels.apply(change_label)\n",
    "    df_labels.head()\n",
    "    return df_labels\n",
    "\n",
    "Y_train = reformat_label(Y_train)\n",
    "Y_val = reformat_label(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have to make each label a single vector \n",
    "# I can just rotate (transpose, since now I have a single rolumn, I will make it into many rows)! \n",
    "Y_train = np.array([Y_train]).T\n",
    "Y_val = np.array([Y_val]).T\n",
    "print(Y_train.shape, Y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train_test_split\n",
    "\n",
    "##### I'll split into train and val, and then tensorflow will split for me in train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "X_train,Y_train = shuffle(X_train, Y_train, random_state=0)\n",
    "X_val,Y_val = shuffle(X_val, Y_val, random_state=0)\n",
    "X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu',\n",
    "          kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
    "    Dropout(0.1),\n",
    "    Dense(units=4, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### checkpoints are like saving the model, but at different epochs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"model_checkpoints/augmented.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    #everytime the accuracy gets better, it saves\n",
    "    save_freq='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitting\n",
    "history = model.fit(X_train,Y_train, epochs=20, validation_data=(X_val,Y_val), callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_val,Y_val)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"saved_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = np.array([[0.4981820583343506,0.3041764795780182,-0.39641207456588745,0.9999492764472961,0.5154309272766113,0.2550220787525177,-0.34935909509658813,0.9998473525047302,0.5238351225852966,0.2552952766418457,-0.34945884346961975,0.9998874068260193,0.5324825644493103,0.25629663467407227,-0.3490661680698395,0.9998465776443481,0.480642706155777,0.258960485458374,-0.35233527421951294,0.9998729228973389,0.46913933753967285,0.26167136430740356,-0.3522539734840393,0.9999103546142578,0.4588560163974762,0.26559099555015564,-0.35270392894744873,0.9998877644538879,0.5477309823036194,0.2884930372238159,-0.08250369131565094,0.9998624324798584,0.44203734397888184,0.2937893569469452,-0.08980625122785568,0.9999209046363831,0.5207302570343018,0.3572015166282654,-0.2996494770050049,0.9999455809593201,0.4778904318809509,0.35783419013023376,-0.303683340549469,0.9999536871910095,0.6314497590065002,0.5698841214179993,0.008182904683053493,0.9999152421951294,0.37602466344833374,0.5611208081245422,0.020433634519577026,0.9998253583908081,0.7292965650558472,0.9798671007156372,-0.32061514258384705,0.9971438646316528,0.20657332241535187,0.8604757785797119,-0.35482174158096313,0.9956580996513367,0.5498597621917725,0.8489202857017517,-0.7637590169906616,0.9986798167228699,0.37362605333328247,0.6491265296936035,-0.8803924322128296,0.9952695369720459,0.4984210431575775,0.8526077270507812,-0.8525819778442383,0.9939749836921692,0.4279037117958069,0.6301683187484741,-0.9744688868522644,0.9816589951515198,0.49681568145751953,0.7763991355895996,-0.7786155939102173,0.9938353300094604,0.43934187293052673,0.5735072493553162,-0.9105846285820007,0.9798092246055603,0.5083235502243042,0.7676472067832947,-0.7398286461830139,0.991555392742157,0.4291306436061859,0.581972599029541,-0.8635354042053223,0.9797517657279968,0.5966092348098755,1.2567808628082275,-0.008524066768586636,0.1589588075876236,0.38996055722236633,1.2599668502807617,0.010765359736979008,0.17815829813480377,0.5948789715766907,1.8001701831817627,0.003953699953854084,0.012086698785424232,0.4031899869441986,1.7931101322174072,-0.015372313559055328,0.00784522294998169,0.6021834015846252,2.2724609375,0.30393192172050476,0.0014408509014174342,0.42258867621421814,2.2609975337982178,0.15069334208965302,0.0005837850621901453,0.6074386835098267,2.337127685546875,0.3106561303138733,0.0007881768397055566,0.41845861077308655,2.323322296142578,0.15600086748600006,0.0007185556460171938,0.5843966603279114,2.4317216873168945,-0.0522509329020977,0.0006601922796107829,0.4535377621650696,2.422938585281372,-0.2161559760570526,0.001258615986444056,0.373634397983551,0.6499707102775574,-1.8444630711655918e-07,0.0,0.39679813385009766,0.5777179598808289,0.0013798748841509223,0.0,0.43735894560813904,0.534506618976593,-0.00420121755450964,0.0,0.47639840841293335,0.5254983901977539,-0.01024630106985569,0.0,0.5027356743812561,0.5411986708641052,-0.014173091389238834,0.0,0.45060163736343384,0.5403348207473755,-0.015738490968942642,0.0,0.5017736554145813,0.5638222098350525,-0.02503901533782482,0.0,0.4914117455482483,0.5653451681137085,-0.027088096365332603,0.0,0.47413501143455505,0.564212441444397,-0.0264134518802166,0.0,0.4494023323059082,0.5912742614746094,-0.021495746448636055,0.0,0.5018069744110107,0.6102883815765381,-0.025984806939959526,0.0,0.4879333972930908,0.6084942817687988,-0.0215410478413105,0.0,0.46763357520103455,0.6072394847869873,-0.018301531672477722,0.0,0.44739097356796265,0.6418318152427673,-0.02643604204058647,0.0,0.4959167242050171,0.6526373028755188,-0.02697780914604664,0.0,0.48271769285202026,0.6494451761245728,-0.015943871811032295,0.0,0.46350032091140747,0.6479849815368652,-0.009380415081977844,0.0,0.4440409541130066,0.686765730381012,-0.03130561113357544,0.0,0.48238319158554077,0.6835903525352478,-0.027893563732504845,0.0,0.4705689549446106,0.6809285879135132,-0.01684371940791607,0.0,0.4541867673397064,0.6818298101425171,-0.009424922056496143,0.0,0.5541528463363647,0.8231633305549622,-1.2188849041194771e-07,0.0,0.5286245942115784,0.7567625045776367,0.002618174534291029,0.0,0.490420401096344,0.725986659526825,-0.0019848633091896772,0.0,0.45551788806915283,0.727816104888916,-0.006525832694023848,0.0,0.4336313307285309,0.7500261068344116,-0.011036446318030357,0.0,0.4799780249595642,0.7299957275390625,-0.022469153627753258,0.0,0.4273468255996704,0.7438825368881226,-0.032165635377168655,0.0,0.4391612410545349,0.7527205348014832,-0.0347185879945755,0.0,0.4578348398208618,0.7505552768707275,-0.034520745277404785,0.0,0.4814111292362213,0.783324658870697,-0.027409298345446587,0.0,0.4299897849559784,0.79166579246521,-0.032714203000068665,0.0,0.4421943128108978,0.7919579744338989,-0.02897382713854313,0.0,0.4601382911205292,0.789323091506958,-0.02673531323671341,0.0,0.4840109646320343,0.8338181972503662,-0.03076060861349106,0.0,0.4401523470878601,0.8343431949615479,-0.032595742493867874,0.0,0.45229482650756836,0.8290730118751526,-0.02321871742606163,0.0,0.467772513628006,0.826426088809967,-0.01786368153989315,0.0,0.4874705970287323,0.8772450685501099,-0.03356040641665459,0.0,0.4529787600040436,0.8700811266899109,-0.03298313543200493,0.0,0.4627114236354828,0.8613516688346863,-0.02354632131755352,0.0,0.4751517176628113,0.8603678345680237,-0.016946855932474136,0.0]])\n",
    "#this is coffee\n",
    "\n",
    "model.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('accuracy_4_labels_regularization.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss_4_labels_regularization.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## THis is the model I had written in the past\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential([\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=64, activation='relu'),\n",
    "    Dense(units=4, activation='softmax')\n",
    "])\n",
    "model2.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(X_train,Y_train, epochs=20, validation_data=(X_val,Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history2.history['accuracy'])\n",
    "plt.plot(history2.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('accuracy_4_labels_no_regularization.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history2.history['loss'])\n",
    "plt.plot(history2.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.savefig('loss_4_labels_no_regularization.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
