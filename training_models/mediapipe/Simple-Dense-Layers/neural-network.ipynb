{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras import Sequential\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      class        x1        y1        z1        v1        x2        y2  \\\n",
            "0    coffee  0.490560  0.290803 -0.457349  0.999989  0.507861  0.251743   \n",
            "1    coffee  0.490317  0.296208 -0.467214  0.999987  0.507768  0.253555   \n",
            "2    coffee  0.490271  0.300322 -0.470750  0.999986  0.507730  0.255209   \n",
            "3    coffee  0.490268  0.302454 -0.487628  0.999985  0.507728  0.256161   \n",
            "4    coffee  0.490803  0.303688 -0.505418  0.999985  0.507995  0.256749   \n",
            "..      ...       ...       ...       ...       ...       ...       ...   \n",
            "110  coffee  0.496863  0.302861 -0.649061  0.999965  0.513863  0.255302   \n",
            "111  coffee  0.496631  0.301382 -0.643764  0.999955  0.513532  0.254744   \n",
            "112  coffee  0.496510  0.300023 -0.687388  0.999919  0.513147  0.254390   \n",
            "113  coffee  0.496565  0.299678 -0.744448  0.999876  0.513067  0.254359   \n",
            "114  coffee  0.496665  0.299629 -0.655965  0.999852  0.513007  0.254376   \n",
            "\n",
            "           z2        v2        x3  ...       z73  v73       x74       y74  \\\n",
            "0   -0.412709  0.999987  0.516950  ... -0.039968  0.0  0.496138  0.838479   \n",
            "1   -0.425430  0.999984  0.516758  ... -0.032240  0.0  0.499593  0.842492   \n",
            "2   -0.429952  0.999982  0.516656  ... -0.032046  0.0  0.501178  0.847488   \n",
            "3   -0.446110  0.999981  0.516634  ... -0.032033  0.0  0.500290  0.853992   \n",
            "4   -0.462483  0.999980  0.516718  ... -0.031262  0.0  0.500826  0.858976   \n",
            "..        ...       ...       ...  ...       ...  ...       ...       ...   \n",
            "110 -0.599471  0.999905  0.523044  ...  0.000000  0.0  0.000000  0.000000   \n",
            "111 -0.594247  0.999894  0.522931  ...  0.000000  0.0  0.000000  0.000000   \n",
            "112 -0.633070  0.999848  0.522765  ...  0.000000  0.0  0.000000  0.000000   \n",
            "113 -0.690254  0.999778  0.522710  ...  0.000000  0.0  0.000000  0.000000   \n",
            "114 -0.606255  0.999730  0.522649  ...  0.000000  0.0  0.000000  0.000000   \n",
            "\n",
            "          z74  v74       x75       y75       z75  v75  \n",
            "0   -0.032200  0.0  0.510814  0.841485 -0.026400  0.0  \n",
            "1   -0.023976  0.0  0.513295  0.845279 -0.018187  0.0  \n",
            "2   -0.023551  0.0  0.515599  0.849821 -0.017611  0.0  \n",
            "3   -0.023843  0.0  0.514286  0.856211 -0.018308  0.0  \n",
            "4   -0.022877  0.0  0.514729  0.861247 -0.017345  0.0  \n",
            "..        ...  ...       ...       ...       ...  ...  \n",
            "110  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "111  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "112  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "113  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "114  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "\n",
            "[115 rows x 301 columns]\n",
            "      class        x1        y1        z1        v1        x2        y2  \\\n",
            "0    coffee  0.515050  0.337479 -0.798418  0.999485  0.524108  0.302156   \n",
            "1    coffee  0.514914  0.337661 -0.793975  0.999504  0.524079  0.302088   \n",
            "2    coffee  0.514846  0.337965 -0.765427  0.999515  0.524072  0.302107   \n",
            "3    coffee  0.514829  0.337725 -0.752842  0.999517  0.524080  0.301461   \n",
            "4    coffee  0.514829  0.337339 -0.762397  0.999538  0.524121  0.300769   \n",
            "..      ...       ...       ...       ...       ...       ...       ...   \n",
            "128  coffee  0.521676  0.344556 -0.683892  0.999849  0.530007  0.306479   \n",
            "129  coffee  0.521711  0.342648 -0.677706  0.999824  0.529994  0.304427   \n",
            "130  coffee  0.521753  0.340865 -0.724294  0.999812  0.529988  0.302698   \n",
            "131  coffee  0.521865  0.340134 -0.748141  0.999800  0.529992  0.301843   \n",
            "132  coffee  0.521859  0.339480 -0.760473  0.999797  0.529952  0.301268   \n",
            "\n",
            "           z2        v2        x3  ...  z73  v73  x74  y74  z74  v74  x75  \\\n",
            "0   -0.776017  0.999213  0.530822  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "1   -0.771250  0.999240  0.530775  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "2   -0.741962  0.999251  0.530759  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "3   -0.728369  0.999248  0.530767  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "4   -0.738645  0.999275  0.530822  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "..        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
            "128 -0.654448  0.999747  0.537098  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "129 -0.648444  0.999701  0.537077  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "130 -0.696996  0.999678  0.537062  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "131 -0.721926  0.999652  0.537061  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "132 -0.734102  0.999645  0.537028  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
            "\n",
            "     y75  z75  v75  \n",
            "0    0.0  0.0  0.0  \n",
            "1    0.0  0.0  0.0  \n",
            "2    0.0  0.0  0.0  \n",
            "3    0.0  0.0  0.0  \n",
            "4    0.0  0.0  0.0  \n",
            "..   ...  ...  ...  \n",
            "128  0.0  0.0  0.0  \n",
            "129  0.0  0.0  0.0  \n",
            "130  0.0  0.0  0.0  \n",
            "131  0.0  0.0  0.0  \n",
            "132  0.0  0.0  0.0  \n",
            "\n",
            "[133 rows x 301 columns]\n",
            "      class        x1        y1        z1        v1        x2        y2  \\\n",
            "0    coffee  0.490560  0.290803 -0.457349  0.999989  0.507861  0.251743   \n",
            "1    coffee  0.490317  0.296208 -0.467214  0.999987  0.507768  0.253555   \n",
            "2    coffee  0.490271  0.300322 -0.470750  0.999986  0.507730  0.255209   \n",
            "3    coffee  0.490268  0.302454 -0.487628  0.999985  0.507728  0.256161   \n",
            "4    coffee  0.490803  0.303688 -0.505418  0.999985  0.507995  0.256749   \n",
            "..      ...       ...       ...       ...       ...       ...       ...   \n",
            "128  coffee  0.521676  0.344556 -0.683892  0.999849  0.530007  0.306479   \n",
            "129  coffee  0.521711  0.342648 -0.677706  0.999824  0.529994  0.304427   \n",
            "130  coffee  0.521753  0.340865 -0.724294  0.999812  0.529988  0.302698   \n",
            "131  coffee  0.521865  0.340134 -0.748141  0.999800  0.529992  0.301843   \n",
            "132  coffee  0.521859  0.339480 -0.760473  0.999797  0.529952  0.301268   \n",
            "\n",
            "           z2        v2        x3  ...       z73  v73       x74       y74  \\\n",
            "0   -0.412709  0.999987  0.516950  ... -0.039968  0.0  0.496138  0.838479   \n",
            "1   -0.425430  0.999984  0.516758  ... -0.032240  0.0  0.499593  0.842492   \n",
            "2   -0.429952  0.999982  0.516656  ... -0.032046  0.0  0.501178  0.847488   \n",
            "3   -0.446110  0.999981  0.516634  ... -0.032033  0.0  0.500290  0.853992   \n",
            "4   -0.462483  0.999980  0.516718  ... -0.031262  0.0  0.500826  0.858976   \n",
            "..        ...       ...       ...  ...       ...  ...       ...       ...   \n",
            "128 -0.654448  0.999747  0.537098  ...  0.000000  0.0  0.000000  0.000000   \n",
            "129 -0.648444  0.999701  0.537077  ...  0.000000  0.0  0.000000  0.000000   \n",
            "130 -0.696996  0.999678  0.537062  ...  0.000000  0.0  0.000000  0.000000   \n",
            "131 -0.721926  0.999652  0.537061  ...  0.000000  0.0  0.000000  0.000000   \n",
            "132 -0.734102  0.999645  0.537028  ...  0.000000  0.0  0.000000  0.000000   \n",
            "\n",
            "          z74  v74       x75       y75       z75  v75  \n",
            "0   -0.032200  0.0  0.510814  0.841485 -0.026400  0.0  \n",
            "1   -0.023976  0.0  0.513295  0.845279 -0.018187  0.0  \n",
            "2   -0.023551  0.0  0.515599  0.849821 -0.017611  0.0  \n",
            "3   -0.023843  0.0  0.514286  0.856211 -0.018308  0.0  \n",
            "4   -0.022877  0.0  0.514729  0.861247 -0.017345  0.0  \n",
            "..        ...  ...       ...       ...       ...  ...  \n",
            "128  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "129  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "130  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "131  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "132  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "\n",
            "[248 rows x 301 columns]\n"
          ]
        }
      ],
      "source": [
        "#import the data ---> these lines are just testing.\n",
        "test = pd.read_csv(\"data_four_labels/coffee/_wijo648v0g3208.csv\")\n",
        "print(test)\n",
        "\n",
        "test2=pd.read_csv(\"data_four_labels/coffee/2sGQuduhAf41354.csv\")\n",
        "print(test2)\n",
        "\n",
        "final_df=pd.concat([test,test2])\n",
        "print(final_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "coffee\n",
            "dog\n",
            "door\n",
            "milk\n",
            "(9776, 301) (3667, 301)\n",
            "training set:\n",
            "     class        x1        y1        z1        v1        x2        y2  \\\n",
            "0   coffee  0.606142  0.244242 -0.815652  0.999938  0.623723  0.211371   \n",
            "1   coffee  0.606009  0.244254 -0.815749  0.999938  0.623691  0.211367   \n",
            "2   coffee  0.605101  0.244437 -0.754448  0.999933  0.623574  0.211543   \n",
            "3   coffee  0.602850  0.244439 -0.760619  0.999929  0.622494  0.211495   \n",
            "4   coffee  0.602109  0.244449 -0.827007  0.999929  0.622169  0.211413   \n",
            "..     ...       ...       ...       ...       ...       ...       ...   \n",
            "75    milk  0.497894  0.306149 -0.517604  0.999934  0.515566  0.259491   \n",
            "76    milk  0.497847  0.305891 -0.508041  0.999933  0.515531  0.259391   \n",
            "77    milk  0.497788  0.305599 -0.499464  0.999932  0.515466  0.259253   \n",
            "78    milk  0.497708  0.305279 -0.495048  0.999933  0.515386  0.259108   \n",
            "79    milk  0.497436  0.305055 -0.492145  0.999933  0.515184  0.258973   \n",
            "\n",
            "          z2        v2        x3  ...       z73  v73       x74       y74  \\\n",
            "0  -0.776338  0.999922  0.634001  ... -0.036408  0.0  0.659736  0.707858   \n",
            "1  -0.775937  0.999923  0.633704  ... -0.031901  0.0  0.660784  0.701760   \n",
            "2  -0.711242  0.999918  0.633406  ... -0.031837  0.0  0.664421  0.694444   \n",
            "3  -0.722415  0.999914  0.632134  ... -0.033219  0.0  0.666726  0.688564   \n",
            "4  -0.783732  0.999915  0.631638  ... -0.035322  0.0  0.662254  0.690637   \n",
            "..       ...       ...       ...  ...       ...  ...       ...       ...   \n",
            "75 -0.484481  0.999870  0.526420  ...  0.000000  0.0  0.000000  0.000000   \n",
            "76 -0.473689  0.999870  0.526399  ...  0.000000  0.0  0.000000  0.000000   \n",
            "77 -0.464760  0.999870  0.526358  ...  0.000000  0.0  0.000000  0.000000   \n",
            "78 -0.460512  0.999872  0.526302  ...  0.000000  0.0  0.000000  0.000000   \n",
            "79 -0.458362  0.999873  0.526164  ...  0.000000  0.0  0.000000  0.000000   \n",
            "\n",
            "         z74  v74       x75       y75       z75  v75  \n",
            "0  -0.029399  0.0  0.671787  0.705231 -0.024129  0.0  \n",
            "1  -0.027481  0.0  0.672509  0.700027 -0.023272  0.0  \n",
            "2  -0.027150  0.0  0.676313  0.692712 -0.022846  0.0  \n",
            "3  -0.028706  0.0  0.678016  0.686593 -0.024647  0.0  \n",
            "4  -0.030620  0.0  0.674081  0.689211 -0.026338  0.0  \n",
            "..       ...  ...       ...       ...       ...  ...  \n",
            "75  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "76  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "77  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "78  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "79  0.000000  0.0  0.000000  0.000000  0.000000  0.0  \n",
            "\n",
            "[9776 rows x 301 columns]\n",
            "testing set: \n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "\n",
        "train_df = pd.DataFrame()\n",
        "test_df = pd.DataFrame()\n",
        "names = [\"coffee\", \"dog\", \"door\", \"milk\"]\n",
        "i = 0\n",
        "for label in names:\n",
        "    # files = glob.glob(f\"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/data_augmentation/data_four_labels_augmentation/{label}/*.csv\")\n",
        "    files = glob.glob(f\"data_four_labels/{label}/*.csv\")\n",
        "    print(label)\n",
        "    for f in files:\n",
        "        csv = pd.read_csv(f)\n",
        "\n",
        "        #this is in order to separate the training set from the test set (setting 25% of values)\n",
        "        if i%4 != 0:    \n",
        "            train_df = pd.concat([train_df, csv])\n",
        "        else:\n",
        "            test_df = pd.concat([test_df, csv])\n",
        "        i += 1\n",
        "        \n",
        "\n",
        "print(train_df.shape, test_df.shape)\n",
        "print(\"training set:\")\n",
        "print(train_df)\n",
        "print(\"testing set: \")\n",
        "# test_df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Since I am working on varying time frames, I will be concatenating the data into sets of n-frames together as one datapoint\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ok, use lists next time, and then transform into a pandas dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def header(FrameNumber, className):\n",
        "    #at first, only one element, the class name\n",
        "    headerList=[className]\n",
        "    for i in range(FrameNumber):\n",
        "        for val in range(1, num_coords+1):        \n",
        "            headerList += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]\n",
        "            all_frames = all_frames.reshape((len(df), 75, 4))\n",
        "    print(headerList)\n",
        "    return headerList\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### separating the features from the labels (just some testing, not actually used)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def seperate_label(df):\n",
        "    df_features = df.copy()\n",
        "\n",
        "    df_labels = df_features.pop(\"class\")\n",
        "\n",
        "    df_features = np.array(df_features)\n",
        "    # df_labels = np.array(df_labels)\n",
        "    print(df_features.shape)\n",
        "    print(df_labels.shape, type(df_labels))\n",
        "    return df_features, df_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9776, 300)\n",
            "(9776,) <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "X_train, Y_train = seperate_label(train_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3667, 300)\n",
            "(3667,) <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "X_val, Y_val = seperate_label(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mydict = [{'a': 1, 'b': 2, 'c': 3, 'd': 4},\n",
        "#           {'a': 100, 'b': 200, 'c': 300, 'd': 400},\n",
        "#           {'a': 1000, 'b': 2000, 'c': 3000, 'd': 4000 }]\n",
        "# df = pd.DataFrame(mydict)\n",
        "# print(df.head())\n",
        "# mylist = []\n",
        "# mylist.append(df.iloc[1])\n",
        "# for i in mylist:\n",
        "#     print(i)\n",
        "#     # for l in i:\n",
        "#     #     print(l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I\"ll also remap every string to an int\n",
        "per example, \n",
        "through a dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reformat_label(df_labels):    \n",
        "#should be between 0 and 3\n",
        "    dicti={\"coffee\": 0, \"dog\": 1, \"door\": 2, \"milk\": 3}\n",
        "    # for element in df_labels:\n",
        "    #     element = dicti[element]\n",
        "\n",
        "    def change_label(x):\n",
        "        return dicti[x]\n",
        "\n",
        "    df_labels = df_labels.apply(change_label)\n",
        "    df_labels.head()\n",
        "    return df_labels\n",
        "\n",
        "Y_train = reformat_label(Y_train)\n",
        "Y_val = reformat_label(Y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0     0\n",
              " 1     0\n",
              " 2     0\n",
              " 3     0\n",
              " 4     0\n",
              "      ..\n",
              " 75    3\n",
              " 76    3\n",
              " 77    3\n",
              " 78    3\n",
              " 79    3\n",
              " Name: class, Length: 9776, dtype: int64,\n",
              " 0      0\n",
              " 1      0\n",
              " 2      0\n",
              " 3      0\n",
              " 4      0\n",
              "       ..\n",
              " 159    3\n",
              " 160    3\n",
              " 161    3\n",
              " 162    3\n",
              " 163    3\n",
              " Name: class, Length: 3667, dtype: int64)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train, Y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(9776, 1) (3667, 1)\n"
          ]
        }
      ],
      "source": [
        "#I have to make each label a single vector \n",
        "# I can just rotate (transpose, since now I have a single rolumn, I will make it into many rows)! \n",
        "Y_train = np.array([Y_train]).T\n",
        "Y_val = np.array([Y_val]).T\n",
        "print(Y_train.shape, Y_val.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### train_test_split\n",
        "\n",
        "##### I'll split into train and val, and then tensorflow will split for me in train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0.53891486,  0.3667444 , -0.58347023, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.51216543,  0.22902365, -0.50954175, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.48298231,  0.25468689, -0.52562565, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        ...,\n",
              "        [ 0.69303405,  0.32725036, -0.30897957, ...,  0.48944685,\n",
              "         -0.02432649,  0.        ],\n",
              "        [ 0.31904715,  0.31237128, -0.70534962, ...,  0.        ,\n",
              "          0.        ,  0.        ],\n",
              "        [ 0.49790773,  0.20905493, -0.65739161, ...,  0.        ,\n",
              "          0.        ,  0.        ]]),\n",
              " array([[1],\n",
              "        [3],\n",
              "        [3],\n",
              "        ...,\n",
              "        [2],\n",
              "        [1],\n",
              "        [1]], dtype=int64))"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train,Y_train = shuffle(X_train, Y_train, random_state=0)\n",
        "X_val,Y_val = shuffle(X_val, Y_val, random_state=0)\n",
        "X_train, Y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## creating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = Sequential([\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=64, activation='relu',\n",
        "          kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
        "    Dropout(0.1),\n",
        "    Dense(units=512, activation='relu'),\n",
        "    Dense(units=256, activation='relu',\n",
        "          kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=16, activation='relu', \n",
        "          kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
        "    Dense(units=4, activation='softmax')\n",
        "])\n",
        "\n",
        "# model = Sequential([\n",
        "#     Dense(units=128, activation='relu'),\n",
        "#     Dense(units=64, activation='relu',\n",
        "#           kernel_regularizer=keras.regularizers.l1_l2(0.01)),\n",
        "#     Dropout(0.1),\n",
        "#     Dense(units=4, activation='softmax')\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "#cost function\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### checkpoints are like saving the model, but at different epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    # \"/Users/aly/Documents/Programming/Apps/Machine Learning/ASL Converter/training_models/mediapipe/Simple-Dense-Layers/AUGMENTED-regularized.{epoch:02d}-{val_accuracy:.2f}\",\n",
        "    \"Simple-Dense-Layers/AUGMENTED-regularized.{epoch:02d}-{val_accuracy:.2f}\",\n",
        "    monitor='val_accuracy',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    #everytime the accuracy gets better, it saves\n",
        "    save_freq='epoch',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "295/306 [===========================>..] - ETA: 0s - loss: 10.2274 - accuracy: 0.4592INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.01-0.44\\assets\n",
            "306/306 [==============================] - 7s 14ms/step - loss: 9.9259 - accuracy: 0.4605 - val_loss: 1.5729 - val_accuracy: 0.4415\n",
            "Epoch 2/50\n",
            "298/306 [============================>.] - ETA: 0s - loss: 1.3401 - accuracy: 0.5220INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.02-0.50\\assets\n",
            "306/306 [==============================] - 3s 11ms/step - loss: 1.3393 - accuracy: 0.5227 - val_loss: 1.4078 - val_accuracy: 0.4996\n",
            "Epoch 3/50\n",
            "304/306 [============================>.] - ETA: 0s - loss: 1.2499 - accuracy: 0.5432INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.03-0.52\\assets\n",
            "306/306 [==============================] - 3s 10ms/step - loss: 1.2495 - accuracy: 0.5431 - val_loss: 1.3567 - val_accuracy: 0.5247\n",
            "Epoch 4/50\n",
            "295/306 [===========================>..] - ETA: 0s - loss: 1.1867 - accuracy: 0.5823INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.04-0.54\\assets\n",
            "306/306 [==============================] - 3s 10ms/step - loss: 1.1859 - accuracy: 0.5824 - val_loss: 1.3275 - val_accuracy: 0.5416\n",
            "Epoch 5/50\n",
            "297/306 [============================>.] - ETA: 0s - loss: 1.1251 - accuracy: 0.6040INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.05-0.54\\assets\n",
            "306/306 [==============================] - 3s 10ms/step - loss: 1.1260 - accuracy: 0.6031 - val_loss: 1.3455 - val_accuracy: 0.5446\n",
            "Epoch 6/50\n",
            "299/306 [============================>.] - ETA: 0s - loss: 1.0955 - accuracy: 0.6119INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.06-0.58\\assets\n",
            "306/306 [==============================] - 3s 11ms/step - loss: 1.0956 - accuracy: 0.6114 - val_loss: 1.2968 - val_accuracy: 0.5765\n",
            "Epoch 7/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 1.0617 - accuracy: 0.6260 - val_loss: 1.2844 - val_accuracy: 0.5683\n",
            "Epoch 8/50\n",
            "299/306 [============================>.] - ETA: 0s - loss: 1.0466 - accuracy: 0.6345INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.08-0.58\\assets\n",
            "306/306 [==============================] - 3s 10ms/step - loss: 1.0471 - accuracy: 0.6348 - val_loss: 1.2908 - val_accuracy: 0.5833\n",
            "Epoch 9/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 1.0281 - accuracy: 0.6377 - val_loss: 1.3017 - val_accuracy: 0.5719\n",
            "Epoch 10/50\n",
            "303/306 [============================>.] - ETA: 0s - loss: 1.0137 - accuracy: 0.6407INFO:tensorflow:Assets written to: Simple-Dense-Layers\\AUGMENTED-regularized.10-0.61\\assets\n",
            "306/306 [==============================] - 3s 11ms/step - loss: 1.0133 - accuracy: 0.6399 - val_loss: 1.2848 - val_accuracy: 0.6054\n",
            "Epoch 11/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 1.0150 - accuracy: 0.6400 - val_loss: 1.2949 - val_accuracy: 0.5724\n",
            "Epoch 12/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.9938 - accuracy: 0.6444 - val_loss: 1.2907 - val_accuracy: 0.5569\n",
            "Epoch 13/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.9865 - accuracy: 0.6470 - val_loss: 1.2749 - val_accuracy: 0.5664\n",
            "Epoch 14/50\n",
            "306/306 [==============================] - 2s 6ms/step - loss: 0.9799 - accuracy: 0.6518 - val_loss: 1.2732 - val_accuracy: 0.5590\n",
            "Epoch 15/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.9687 - accuracy: 0.6614 - val_loss: 1.2578 - val_accuracy: 0.5879\n",
            "Epoch 16/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9603 - accuracy: 0.6690 - val_loss: 1.3220 - val_accuracy: 0.5151\n",
            "Epoch 17/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9519 - accuracy: 0.6718 - val_loss: 1.3826 - val_accuracy: 0.5710\n",
            "Epoch 18/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9470 - accuracy: 0.6842 - val_loss: 1.2780 - val_accuracy: 0.5582\n",
            "Epoch 19/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9307 - accuracy: 0.6974 - val_loss: 1.2972 - val_accuracy: 0.5800\n",
            "Epoch 20/50\n",
            "306/306 [==============================] - 2s 6ms/step - loss: 0.9224 - accuracy: 0.7056 - val_loss: 1.3588 - val_accuracy: 0.5528\n",
            "Epoch 21/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9116 - accuracy: 0.7159 - val_loss: 1.3499 - val_accuracy: 0.5547\n",
            "Epoch 22/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.9081 - accuracy: 0.7223 - val_loss: 1.3666 - val_accuracy: 0.5566\n",
            "Epoch 23/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.8911 - accuracy: 0.7352 - val_loss: 1.3404 - val_accuracy: 0.5858\n",
            "Epoch 24/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.8720 - accuracy: 0.7456 - val_loss: 1.4576 - val_accuracy: 0.5560\n",
            "Epoch 25/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.8710 - accuracy: 0.7495 - val_loss: 1.4105 - val_accuracy: 0.5604\n",
            "Epoch 26/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.8496 - accuracy: 0.7638 - val_loss: 1.3529 - val_accuracy: 0.5888\n",
            "Epoch 27/50\n",
            "306/306 [==============================] - 1s 4ms/step - loss: 0.8449 - accuracy: 0.7662 - val_loss: 1.5413 - val_accuracy: 0.5569\n",
            "Epoch 28/50\n",
            "306/306 [==============================] - 1s 4ms/step - loss: 0.8381 - accuracy: 0.7752 - val_loss: 1.4375 - val_accuracy: 0.6027\n",
            "Epoch 29/50\n",
            "306/306 [==============================] - 1s 4ms/step - loss: 0.8193 - accuracy: 0.7828 - val_loss: 1.4730 - val_accuracy: 0.5669\n",
            "Epoch 30/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.8062 - accuracy: 0.7893 - val_loss: 1.5285 - val_accuracy: 0.5803\n",
            "Epoch 31/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7991 - accuracy: 0.7957 - val_loss: 1.6387 - val_accuracy: 0.5593\n",
            "Epoch 32/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7805 - accuracy: 0.8034 - val_loss: 1.5984 - val_accuracy: 0.5787\n",
            "Epoch 33/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7804 - accuracy: 0.8060 - val_loss: 1.6391 - val_accuracy: 0.5822\n",
            "Epoch 34/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7652 - accuracy: 0.8155 - val_loss: 1.5628 - val_accuracy: 0.5800\n",
            "Epoch 35/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7564 - accuracy: 0.8178 - val_loss: 1.8882 - val_accuracy: 0.5650\n",
            "Epoch 36/50\n",
            "306/306 [==============================] - 2s 6ms/step - loss: 0.7540 - accuracy: 0.8185 - val_loss: 1.8592 - val_accuracy: 0.5708\n",
            "Epoch 37/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7368 - accuracy: 0.8264 - val_loss: 1.9225 - val_accuracy: 0.5645\n",
            "Epoch 38/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7470 - accuracy: 0.8233 - val_loss: 1.7556 - val_accuracy: 0.5664\n",
            "Epoch 39/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7281 - accuracy: 0.8277 - val_loss: 1.9828 - val_accuracy: 0.5699\n",
            "Epoch 40/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.7396 - accuracy: 0.8262 - val_loss: 1.7089 - val_accuracy: 0.5852\n",
            "Epoch 41/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7144 - accuracy: 0.8360 - val_loss: 1.8999 - val_accuracy: 0.5751\n",
            "Epoch 42/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7217 - accuracy: 0.8296 - val_loss: 1.9354 - val_accuracy: 0.5683\n",
            "Epoch 43/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7201 - accuracy: 0.8318 - val_loss: 1.8589 - val_accuracy: 0.5754\n",
            "Epoch 44/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7022 - accuracy: 0.8418 - val_loss: 1.8253 - val_accuracy: 0.5839\n",
            "Epoch 45/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.6995 - accuracy: 0.8406 - val_loss: 2.0261 - val_accuracy: 0.5757\n",
            "Epoch 46/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.7001 - accuracy: 0.8408 - val_loss: 2.0244 - val_accuracy: 0.5525\n",
            "Epoch 47/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.6854 - accuracy: 0.8470 - val_loss: 1.9435 - val_accuracy: 0.5721\n",
            "Epoch 48/50\n",
            "306/306 [==============================] - 1s 5ms/step - loss: 0.6889 - accuracy: 0.8435 - val_loss: 2.0220 - val_accuracy: 0.5569\n",
            "Epoch 49/50\n",
            "306/306 [==============================] - 2s 5ms/step - loss: 0.6752 - accuracy: 0.8498 - val_loss: 2.0353 - val_accuracy: 0.5825\n",
            "Epoch 50/50\n",
            "306/306 [==============================] - 2s 6ms/step - loss: 0.6662 - accuracy: 0.8555 - val_loss: 1.9476 - val_accuracy: 0.5751\n"
          ]
        }
      ],
      "source": [
        "#fitting\n",
        "history = model.fit(X_train,Y_train, epochs=50, validation_data=(X_val,Y_val), callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "115/115 [==============================] - 0s 2ms/step - loss: 1.9476 - accuracy: 0.5751\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               38528     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               33280     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 128)               32896     \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                2064      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246,420\n",
            "Trainable params: 246,420\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.evaluate(X_val,Y_val)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(\"saved_model\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = np.array([[0.4981820583343506,0.3041764795780182,-0.39641207456588745,0.9999492764472961,0.5154309272766113,0.2550220787525177,-0.34935909509658813,0.9998473525047302,0.5238351225852966,0.2552952766418457,-0.34945884346961975,0.9998874068260193,0.5324825644493103,0.25629663467407227,-0.3490661680698395,0.9998465776443481,0.480642706155777,0.258960485458374,-0.35233527421951294,0.9998729228973389,0.46913933753967285,0.26167136430740356,-0.3522539734840393,0.9999103546142578,0.4588560163974762,0.26559099555015564,-0.35270392894744873,0.9998877644538879,0.5477309823036194,0.2884930372238159,-0.08250369131565094,0.9998624324798584,0.44203734397888184,0.2937893569469452,-0.08980625122785568,0.9999209046363831,0.5207302570343018,0.3572015166282654,-0.2996494770050049,0.9999455809593201,0.4778904318809509,0.35783419013023376,-0.303683340549469,0.9999536871910095,0.6314497590065002,0.5698841214179993,0.008182904683053493,0.9999152421951294,0.37602466344833374,0.5611208081245422,0.020433634519577026,0.9998253583908081,0.7292965650558472,0.9798671007156372,-0.32061514258384705,0.9971438646316528,0.20657332241535187,0.8604757785797119,-0.35482174158096313,0.9956580996513367,0.5498597621917725,0.8489202857017517,-0.7637590169906616,0.9986798167228699,0.37362605333328247,0.6491265296936035,-0.8803924322128296,0.9952695369720459,0.4984210431575775,0.8526077270507812,-0.8525819778442383,0.9939749836921692,0.4279037117958069,0.6301683187484741,-0.9744688868522644,0.9816589951515198,0.49681568145751953,0.7763991355895996,-0.7786155939102173,0.9938353300094604,0.43934187293052673,0.5735072493553162,-0.9105846285820007,0.9798092246055603,0.5083235502243042,0.7676472067832947,-0.7398286461830139,0.991555392742157,0.4291306436061859,0.581972599029541,-0.8635354042053223,0.9797517657279968,0.5966092348098755,1.2567808628082275,-0.008524066768586636,0.1589588075876236,0.38996055722236633,1.2599668502807617,0.010765359736979008,0.17815829813480377,0.5948789715766907,1.8001701831817627,0.003953699953854084,0.012086698785424232,0.4031899869441986,1.7931101322174072,-0.015372313559055328,0.00784522294998169,0.6021834015846252,2.2724609375,0.30393192172050476,0.0014408509014174342,0.42258867621421814,2.2609975337982178,0.15069334208965302,0.0005837850621901453,0.6074386835098267,2.337127685546875,0.3106561303138733,0.0007881768397055566,0.41845861077308655,2.323322296142578,0.15600086748600006,0.0007185556460171938,0.5843966603279114,2.4317216873168945,-0.0522509329020977,0.0006601922796107829,0.4535377621650696,2.422938585281372,-0.2161559760570526,0.001258615986444056,0.373634397983551,0.6499707102775574,-1.8444630711655918e-07,0.0,0.39679813385009766,0.5777179598808289,0.0013798748841509223,0.0,0.43735894560813904,0.534506618976593,-0.00420121755450964,0.0,0.47639840841293335,0.5254983901977539,-0.01024630106985569,0.0,0.5027356743812561,0.5411986708641052,-0.014173091389238834,0.0,0.45060163736343384,0.5403348207473755,-0.015738490968942642,0.0,0.5017736554145813,0.5638222098350525,-0.02503901533782482,0.0,0.4914117455482483,0.5653451681137085,-0.027088096365332603,0.0,0.47413501143455505,0.564212441444397,-0.0264134518802166,0.0,0.4494023323059082,0.5912742614746094,-0.021495746448636055,0.0,0.5018069744110107,0.6102883815765381,-0.025984806939959526,0.0,0.4879333972930908,0.6084942817687988,-0.0215410478413105,0.0,0.46763357520103455,0.6072394847869873,-0.018301531672477722,0.0,0.44739097356796265,0.6418318152427673,-0.02643604204058647,0.0,0.4959167242050171,0.6526373028755188,-0.02697780914604664,0.0,0.48271769285202026,0.6494451761245728,-0.015943871811032295,0.0,0.46350032091140747,0.6479849815368652,-0.009380415081977844,0.0,0.4440409541130066,0.686765730381012,-0.03130561113357544,0.0,0.48238319158554077,0.6835903525352478,-0.027893563732504845,0.0,0.4705689549446106,0.6809285879135132,-0.01684371940791607,0.0,0.4541867673397064,0.6818298101425171,-0.009424922056496143,0.0,0.5541528463363647,0.8231633305549622,-1.2188849041194771e-07,0.0,0.5286245942115784,0.7567625045776367,0.002618174534291029,0.0,0.490420401096344,0.725986659526825,-0.0019848633091896772,0.0,0.45551788806915283,0.727816104888916,-0.006525832694023848,0.0,0.4336313307285309,0.7500261068344116,-0.011036446318030357,0.0,0.4799780249595642,0.7299957275390625,-0.022469153627753258,0.0,0.4273468255996704,0.7438825368881226,-0.032165635377168655,0.0,0.4391612410545349,0.7527205348014832,-0.0347185879945755,0.0,0.4578348398208618,0.7505552768707275,-0.034520745277404785,0.0,0.4814111292362213,0.783324658870697,-0.027409298345446587,0.0,0.4299897849559784,0.79166579246521,-0.032714203000068665,0.0,0.4421943128108978,0.7919579744338989,-0.02897382713854313,0.0,0.4601382911205292,0.789323091506958,-0.02673531323671341,0.0,0.4840109646320343,0.8338181972503662,-0.03076060861349106,0.0,0.4401523470878601,0.8343431949615479,-0.032595742493867874,0.0,0.45229482650756836,0.8290730118751526,-0.02321871742606163,0.0,0.467772513628006,0.826426088809967,-0.01786368153989315,0.0,0.4874705970287323,0.8772450685501099,-0.03356040641665459,0.0,0.4529787600040436,0.8700811266899109,-0.03298313543200493,0.0,0.4627114236354828,0.8613516688346863,-0.02354632131755352,0.0,0.4751517176628113,0.8603678345680237,-0.016946855932474136,0.0]])\n",
        "#this is coffee\n",
        "\n",
        "model.predict(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig('accuracy_4_labels_regularization.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig('loss_4_labels_regularization.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## THis is the model I had written in the past\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model2 = Sequential([\n",
        "    Dense(units=128, activation='relu'),\n",
        "    Dense(units=64, activation='relu'),\n",
        "    Dense(units=4, activation='softmax')\n",
        "])\n",
        "model2.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history2 = model2.fit(X_train,Y_train, epochs=20, validation_data=(X_val,Y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.plot(history2.history['accuracy'])\n",
        "plt.plot(history2.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig('accuracy_4_labels_no_regularization.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(history2.history['loss'])\n",
        "plt.plot(history2.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig('loss_4_labels_no_regularization.png')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
