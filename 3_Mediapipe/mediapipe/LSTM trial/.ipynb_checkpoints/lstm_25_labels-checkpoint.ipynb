{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "725c0e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 23:06:34.620553: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-07 23:06:35.152036: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "592591b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95cd3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 23:06:37.849700: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-07 23:06:37.878118: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-07-07 23:06:37.878388: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81d9a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator\n",
    "class AugmentedDataGenerator(tf.keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 batch_size=32,\n",
    "                 root_dir=r\"/Tmp/shariffa/ASL-words-translator/6_Databases/Aug25LabelsData/train\",\n",
    "                 input_shape=(211, 300),\n",
    "                 shuffle=True,\n",
    "                labels={'hear': 0,\n",
    " 'music': 1,\n",
    " 'bookstore': 2,\n",
    " 'classroom': 3,\n",
    " 'doctor': 4,\n",
    " 'focus': 5,\n",
    " 'chicken': 6,\n",
    " 'door': 7,\n",
    " 'many': 8,\n",
    " 'polite': 9,\n",
    " 'good morning': 10,\n",
    " 'coffee': 11,\n",
    " 'photographer': 12,\n",
    " 'hamburger': 13,\n",
    " 'i': 14,\n",
    " 'phone': 15,\n",
    " 'brother': 16,\n",
    " 'i love you': 17,\n",
    " 'milk': 18,\n",
    " 'dog': 19,\n",
    " 'ocean': 20,\n",
    " 'research': 21,\n",
    " 'book': 22,\n",
    " 'open': 23,\n",
    " 'money': 24}):\n",
    "#         \n",
    "        self.root_dir = root_dir\n",
    "        print(self.root_dir)\n",
    "        self.batch_size = batch_size\n",
    "        self.input_shape = input_shape\n",
    "        self.labels=labels\n",
    "        count = 0\n",
    "        for root_dir, cur_dir, files in os.walk(self.root_dir):\n",
    "            count += len(files)\n",
    "        print('file count:', count)\n",
    "        self.n = count\n",
    "        self.fileList = self.__create_file_list(self.root_dir, shuffle)\n",
    "    def __create_file_list(self, root_dir, shuffle):\n",
    "        count = 0\n",
    "        fileList = []\n",
    "        for label in os.listdir(root_dir):\n",
    "            if label in self.labels:\n",
    "                for file in os.listdir(os.path.join(root_dir, label)):\n",
    "                    fileList.append((file, label))\n",
    "        if shuffle:\n",
    "            random.shuffle(fileList)\n",
    "        return fileList\n",
    "    \n",
    "    def process_csv_file(self, fileTuple):\n",
    "        file, label = fileTuple\n",
    "        filePath = os.path.join(self.root_dir, label, file)\n",
    "        try:\n",
    "            csv_data = pd.read_csv(filePath)\n",
    "        except:\n",
    "            print(\"CANT READ CSV: \", filePath)\n",
    "            return\n",
    "\n",
    "        if csv_data.isnull().values.any():    \n",
    "            return False\n",
    "        try:\n",
    "            csv_data = csv_data.drop(\"class\", axis = 1)\n",
    "        except KeyError:\n",
    "            pass\n",
    "        return (csv_data.to_numpy(), label)\n",
    "    \n",
    "    def set_padding(self, arr, max_length):\n",
    "        arr = np.append(arr, np.zeros((max_length-arr.shape[0],300)), axis=0)\n",
    "        return np.expand_dims(arr, 0)\n",
    "    def __get_data(self, filesToProcess):\n",
    "        X = np.empty((0, self.input_shape[0], self.input_shape[1]))\n",
    "        Y = np.empty((0,), int)\n",
    "        for fileTuple in filesToProcess:\n",
    "            try:\n",
    "                data, label = self.process_csv_file(fileTuple)\n",
    "                data = self.set_padding(data, max_length=self.input_shape[0])\n",
    "                X = np.append(X, data, axis=0)\n",
    "                Y = np.append(Y, self.labels[label])\n",
    "\n",
    "            except TypeError:\n",
    "                pass\n",
    "#                 print(fileTuple)\n",
    "        return X, Y\n",
    "    def on_epoch_end(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        filesToProcess = self.fileList[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batchX, batchY = self.__get_data(filesToProcess)\n",
    "        return batchX, batchY\n",
    "    def __len__(self):\n",
    "        return self.n // self.batch_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8a6afd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hear': 0,\n",
       " 'music': 1,\n",
       " 'bookstore': 2,\n",
       " 'classroom': 3,\n",
       " 'doctor': 4,\n",
       " 'focus': 5,\n",
       " 'chicken': 6,\n",
       " 'door': 7,\n",
       " 'many': 8,\n",
       " 'polite': 9,\n",
       " 'good morning': 10,\n",
       " 'coffee': 11,\n",
       " 'photographer': 12,\n",
       " 'hamburger': 13,\n",
       " 'i': 14,\n",
       " 'phone': 15,\n",
       " 'brother': 16,\n",
       " 'i love you': 17,\n",
       " 'milk': 18,\n",
       " 'dog': 19,\n",
       " 'ocean': 20,\n",
       " 'research': 21,\n",
       " 'book': 22,\n",
       " 'open': 23,\n",
       " 'money': 24}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_labels(folder_path):\n",
    "    labels = {}\n",
    "    count = 0\n",
    "    for folder in os.listdir(folder_path):\n",
    "            labels[folder] = count\n",
    "            count += 1\n",
    "    return labels\n",
    "\n",
    "labels = get_labels(\"/Tmp/shariffa/ASL-words-translator/6_Databases/Aug25LabelsData/train\")\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b95e8d4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Tmp/shariffa/ASL-words-translator/6_Databases/Aug25LabelsData/train\n",
      "file count: 42720\n",
      "/Tmp/shariffa/ASL-words-translator/6_Databases/Aug25LabelsData/test\n",
      "file count: 9120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('0bIF7jh6lnE4677_projective_geo_6_True_0__2_.csv', 'door'),\n",
       " ('_wijo648v0g3092_projective_geo_13_True_reflexion_0_.csv', 'milk'),\n",
       " ('E3ILIbZqcKY3566_projective_geo_9_False_reflexion_3_.csv', 'dog'),\n",
       " ('2sGQuduhAf43239_projective_geo_13_False_reflexion_0__1__2__3_.csv', 'milk'),\n",
       " ('0bIF7jh6lnE4639_projective_geo_14_True_0_.csv', 'door')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = AugmentedDataGenerator()\n",
    "test_data = AugmentedDataGenerator(root_dir=r\"/Tmp/shariffa/ASL-words-translator/6_Databases/Aug25LabelsData/test\",\n",
    "                                  batch_size=32)\n",
    "train_data.fileList[0:5]\n",
    "test_data.fileList[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "028f03fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.48266143,  0.25151151, -0.66583532, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48195514,  0.25146753, -0.66424268, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48045793,  0.25147596, -0.65664881, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        ...,\n",
       "        [ 0.48019916,  0.24556774, -0.64471287, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48011598,  0.24555989, -0.65619022, ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.48010522,  0.24555062, -0.66737396, ...,  0.        ,\n",
       "          0.        ,  0.        ]]),\n",
       " 'book')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test if the process_csv_file method works\n",
    "file = \"41X2t_s2Ai40.csv\"\n",
    "train_data.process_csv_file((file, \"book\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8d99bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 23:07:46.420437: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:07:46.421391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:07:46.422005: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-07 23:07:46.534468: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:07:46.535143: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:07:46.535766: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "#LSTM model - 25 labels\n",
    "from tensorflow.keras import layers\n",
    "x_shape = (457, 211, 300)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
    "\n",
    "model_lstm = Sequential()\n",
    "model_lstm.add(LSTM(64, return_sequences=True, input_shape=(211, 300)))\n",
    "# model_lstm.add(Dropout(0.2))\n",
    "# model_lstm.add(LSTM(128, return_sequences=True))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(LSTM(64, return_sequences=True))\n",
    "# model_lstm.add(LSTM(64, return_sequences=True))\n",
    "model_lstm.add(Flatten())\n",
    "# model_lstm.add(Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(0.01)))\n",
    "# model_lstm.add(Dropout(0.2))\n",
    "# model_lstm.add(Dense(256, activation=\"relu\", ))\n",
    "model_lstm.add(Dense(128, activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(0.01)))\n",
    "# model_lstm.add(Dense(64, activation=\"relu\", kernel_regularizer=keras.regularizers.l1_l2(0.05)))\n",
    "model_lstm.add(Dropout(0.2))\n",
    "model_lstm.add(Dense(64, activation=\"relu\"))\n",
    "model_lstm.add(Dense(32, activation=\"relu\"))\n",
    "model_lstm.add(Dense(25, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f32be826",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
    "    \"/Tmp/shariffa/LSTM-4-labelsNewAug.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "#     \"/Tmp/linxinle/models/LSTM-25-labels.{epoch:02d}-{val_accuracy:.2f}\",\n",
    "\n",
    "    monitor='val_accuracy',\n",
    "    verbose=0,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='auto',\n",
    "    save_freq='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4108ab56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e1f4013c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 23:08:08.329515: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-07 23:08:08.446973: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:08:08.447745: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:08:08.448419: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-07 23:08:08.560782: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:08:08.561572: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:08:08.562356: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-07 23:08:09.381799: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:08:09.382822: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:08:09.383530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-07 23:08:09.495448: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-07 23:08:09.496223: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-07 23:08:09.496898: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "   1/1335 [..............................] - ETA: 1:02:12 - loss: 152.5901 - accuracy: 0.3333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-07 23:08:11.154945: W tensorflow/core/framework/op_kernel.cc:1830] OP_REQUIRES failed at cudnn_rnn_ops.cc:1564 : UNKNOWN: CUDNN_STATUS_BAD_PARAM\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(1665): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\n",
      "2023-07-07 23:08:11.154973: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: CUDNN_STATUS_BAD_PARAM\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(1665): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\n",
      "\t [[{{node CudnnRNN}}]]\n",
      "2023-07-07 23:08:11.155002: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): UNKNOWN: {{function_node __forward_gpu_lstm_with_fallback_16612_specialized_for_sequential_1_lstm_2_PartitionedCall_at___inference_train_function_18506}} {{function_node __forward_gpu_lstm_with_fallback_16612_specialized_for_sequential_1_lstm_2_PartitionedCall_at___inference_train_function_18506}} CUDNN_STATUS_BAD_PARAM\n",
      "in tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(1665): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\n",
      "\t [[{{node CudnnRNN}}]]\n",
      "\t [[sequential_1/lstm_2/PartitionedCall]]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nCUDNN_STATUS_BAD_PARAM\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(1665): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_1/lstm_2/PartitionedCall]] [Op:__inference_train_function_18506]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_lstm\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_lstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Tmp/shariffa/miniconda3/envs/asl-converter/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/Tmp/shariffa/miniconda3/envs/asl-converter/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nCUDNN_STATUS_BAD_PARAM\nin tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc(1665): 'cudnnSetTensorNdDescriptor( tensor_desc.get(), data_type, sizeof(dims) / sizeof(dims[0]), dims, strides)'\n\t [[{{node CudnnRNN}}]]\n\t [[sequential_1/lstm_2/PartitionedCall]] [Op:__inference_train_function_18506]"
     ]
    }
   ],
   "source": [
    "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model_lstm.fit(train_data, epochs=50, validation_data=test_data, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160d9913",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "eb15a2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "d = {\"key1\": 10, \"key2\": 23}\n",
    "if \"key1\" in d:\n",
    "    print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1ffd42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asl-converter",
   "language": "python",
   "name": "asl-converter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
