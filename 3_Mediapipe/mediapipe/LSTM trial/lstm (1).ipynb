{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_csv_file(file):\n",
        "    try:\n",
        "     csv_data = pd.read_csv(file)\n",
        "    except:\n",
        "         print(\"CANT READ CSV: \", file)\n",
        "         return\n",
        "    \n",
        "    if csv_data.isnull().values.any():\n",
        "            \n",
        "            return False\n",
        "    try:\n",
        "        csv_data = csv_data.drop(\"class\", axis = 1)\n",
        "    except KeyError:\n",
        "        pass\n",
        "    return (csv_data.to_numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cd /Tmp/ASL-data/Database-augmented/coffee/; ls;\n",
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = \"/Tmp/ASL-data/Database-augmented/test/coffee/2sGQuduhAf41354.csv\"\n",
        "process_csv_file(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def set_padding(arr, max_length):\n",
        "    arr = np.append(arr, np.zeros((max_length-arr.shape[0],300)), axis=0)\n",
        "    return np.expand_dims(arr, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_data(folder_path, labels, train=True):\n",
        "    total = 0\n",
        "    max_length = 211\n",
        "    \n",
        "    # find max length\n",
        "    # for folder in os.listdir(folder_path):\n",
        "    #     print(folder)\n",
        "    #     if folder != \".DS_Store\":\n",
        "    #         total += len(os.listdir(os.path.join(folder_path, folder)))\n",
        "    #         for file in os.listdir(os.path.join(folder_path, folder)):\n",
        "    #             if file != \".DS_Store\":\n",
        "    #                 data = process_csv_file(os.path.join(folder_path, folder, file))\n",
        "    #                 if data is not(False):\n",
        "    #                     if data.shape[0] > max_length:\n",
        "    #                         max_length = data.shape[0]\n",
        "    # print(max_length)\n",
        "    # Make the arrays\n",
        "    X = np.empty((0, max_length, 300))\n",
        "    Y = np.empty((0,), int)\n",
        "    print(\"----------\")\n",
        "    for folder in os.listdir(folder_path):\n",
        "        print(folder)\n",
        "        if folder != \".DS_Store\":\n",
        "            \n",
        "            i=0\n",
        "            for file in os.listdir(os.path.join(folder_path, folder)):\n",
        "                if file != \".DS_Store\":\n",
        "                    data = process_csv_file(os.path.join(folder_path, folder, file))\n",
        "                    if data is not(False):\n",
        "                        data = set_padding(data, max_length)\n",
        "                        X = np.append(X, data, axis=0)\n",
        "                        Y = np.append(Y, labels[folder])\n",
        "                        if (i% 50 == 0):\n",
        "                            print(i)\n",
        "                    i+=1\n",
        "                if train == True:\n",
        "                    if i == 20:\n",
        "                        break\n",
        "                elif i == 21: # test dataset limit\n",
        "                    break\n",
        "    print(total, max_length)\n",
        "    return X, Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "folder_path_train = \"/Tmp/ASL-data/Database-augmented/train\"\n",
        "labels= {\"coffee\": 0, 'dog': 1, 'milk': 2, 'door': 3}\n",
        "X_train, Y_train = prepare_data(folder_path_train, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folder_path_test = \"/Tmp/ASL-data/Database-augmented/test\"\n",
        "labels = {\"coffee\": 0, 'dog': 1, 'milk': 2, 'door': 3}\n",
        "X_test, Y_test = prepare_data(folder_path_test, labels, train=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    [\n",
        "    [711, 632, 71],\n",
        "    [73, 8, 3215, 55, 927],\n",
        "    [83, 91, 1, 645, 1253, 927],\n",
        "], padding=\"post\"\n",
        ")\n",
        "# print(X[0][1])\n",
        "print(((padded_inputs)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "# Y = np.expand_dims(Y, axis=0)\n",
        "# Y= Y.T\n",
        "Y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shuffle data\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "X_train,Y_train = shuffle(X_train, Y_train, random_state=0)\n",
        "X_val,Y_val = shuffle(X_test, Y_test, random_state=0)\n",
        "X_train, Y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train.shape, Y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_shape = X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "masking_input = []\n",
        "for i in range(x_shape[0]):\n",
        "    masking_input.append(X_train[i].T[0])\n",
        "\n",
        "masking_input = np.array(masking_input)\n",
        "\n",
        "masking_input.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding = layers.Embedding(input_dim=x_shape[1], output_dim=x_shape[1], mask_zero=True)\n",
        "masked_output = embedding(masking_input)\n",
        "\n",
        "print(masked_output._keras_mask)\n",
        "masked_output\n",
        "# masking_layer = layers.Masking()\n",
        "# # Simulate the embedding lookup by expanding the 2D input to 3D,\n",
        "# # with embedding dimension of 10.\n",
        "# unmasked_embedding = tf.cast(\n",
        "#     tf.tile(tf.expand_dims(padded_inputs, axis=-1), [1, 1, 10]), tf.float32\n",
        "# )\n",
        "\n",
        "# masked_embedding = masking_layer(unmasked_embedding)\n",
        "# print(masked_embedding._keras_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#LSTM model \n",
        "from tensorflow.keras import layers\n",
        "x_shape = (457, 211, 300)\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Flatten\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(64, return_sequences=True, input_shape=(211, 300)))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(128, return_sequences=True))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(64))\n",
        "model_lstm.add(Flatten())\n",
        "model_lstm.add(Dense(128, activation=\"relu\"))\n",
        "model_lstm.add(Dense(64, activation=\"relu\"))\n",
        "model_lstm.add(Dense(4, activation='softmax'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "    \"/Tmp/shariffa/LSTM-4-labels.{epoch:02d}-{val_accuracy:.2f}\",\n",
        "    monitor='val_accuracy',\n",
        "    verbose=0,\n",
        "    save_best_only=True,\n",
        "    save_weights_only=False,\n",
        "    mode='auto',\n",
        "    save_freq='epoch',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lstm.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model_lstm.fit(X_train, Y_train, epochs=50, validation_data=(X_val, Y_val), callbacks=[checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = layers.Input(shape=(x_shape[1], x_shape[2]))\n",
        "x = layers.GRU(64)(inputs, mask=masked_output._keras_mask)\n",
        "# x = layers.LSTM(64)(x)\n",
        "outputs = layers.Dense(4, activation=\"softmax\")(x)\n",
        "model_lstm2= tf.keras.Model(inputs, outputs)\n",
        "model_lstm2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_lstm2.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_lstm2.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(64))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "model.compile(loss=SparseCategoricalCrossentropy(), optimizer=Adam(), metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "asl-converter",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
