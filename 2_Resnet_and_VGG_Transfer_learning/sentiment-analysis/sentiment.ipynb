{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There are several databases available for emotion detection using images. Some examples are:\n",
    "\n",
    "# EMOTIC: a database of images with people in real environments, annotated with their apparent emotions1.\n",
    "# CK+: a public benchmark dataset for action units and emotion recognition, with labelled images of 123 individuals1.\n",
    "# Amazon Review Data: a dataset containing product information and customer reviews from 1996 to 20182.\n",
    "# To transform the features of the faces in those images to arrays using MediaPipe, you can use FaceMesh, which estimates 468 3D face landmarks in real-time even on mobile devices3. You can follow this tutorial on how to use FaceMesh with Flutter1.\n",
    "\n",
    "# To find a good model that will efficiently detect the sentiment on a person, you can use some existing models such as:\n",
    "\n",
    "# EmoNet: a deep neural network model that predicts categorical emotions and continuous dimensions from face images.\n",
    "# FER+: an improved version of Microsoftâ€™s FER2013 model that uses transfer learning and label distribution learning to achieve better accuracy on facial expression recognition.\n",
    "# Emotion Recognition API: an online service that provides emotion recognition from face images using deep learning models.\n",
    "# Which database and model do you want to use for your project?"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
